% Tesi D.S.I. - modello preso da
% Stanford University PhD thesis style -- modifications to the report style
\documentclass[a4paper,12pt]{report}
\usepackage[a4paper]{geometry}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage{epsfig}
\usepackage[italian]{babel}
\usepackage{setspace}
\usepackage{tesi}
\usepackage[utf8]{inputenc}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{pythonhighlight}
\usepackage{algpseudocode}
\usepackage{enumitem}
\usepackage{tcolorbox}
\usepackage{listings}
\usepackage{tikz}
\usepackage{framed}
\usepackage{fancyvrb}
\usepackage{listings,lipsum}
\usepackage{graphicx}
\usepackage{lipsum}
\usepackage[a-2b,mathxmp]{pdfx}[2018/12/22]
\tcbuselibrary{listings,breakable}

\newenvironment{teor}{\begin{myteor}\sl}{\end{myteor}}
%
%
%			TITOLO: Furthest Insertion Algorithm 
%
\begin{document}
\includegraphics{tesiSCIENZE_TECNOLOGIE.jpg}
\title{Furthest Insertion: una nuova euristica per il TSP}
\author{Asaf COHEN}
\dept{Corso di Laurea Triennale in Informatica} 
\anno{2023-2024}
\matricola{975599}
\relatore{Chiar.mo Prof. Giovanni RIGHINI}
%
%        \submitdate{month year in which submitted to GPO}
%		- date LaTeX'd if omitted
%	\copyrightyear{year degree conferred (next year if submitted in Dec.)}
%		- year LaTeX'd (or next year, in December) if omitted
%	\copyrighttrue or \copyrightfalse
%		- produce or don't produce a copyright page (false by default)
%	\figurespagetrue or \figurespagefalse
%		- produce or don't produce a List of Figures page
%		  (false by default)
%	\tablespagetrue or \tablespagefalse
%		- produce or don't produce a List of Tables page
%		  (false by default)
% 
%			DEDICA
%

\beforepreface

\clearpage
\null
\thispagestyle{empty}
\clearpage

\prefacesection{Ringraziamenti}
{ \Large {\sl Nel 2020, in piena pandemia, dopo una laurea con lode in pianoforte al Conservatorio di Milano ho preso una decisione molto difficile: iscrivermi alla facoltà di Informatica. Dopo anni di impegno e dedizione costante, questo percorso è arrivato alla conclusione.\newline Prima di tutto vorrei ringraziare il mio relatore, il Professor Giovanni Righini, per il costante supporto durante lo sviluppo del progetto e la stesura della tesi. Le sue indicazioni sono state determinanti per la riuscita del progetto. \newline Un mio pensiero va, ovviamente, alla mia famiglia che mi ha sostenuto e mi ha incoraggiato ad intraprendere questa nuova strada. \newline Un grazie speciale va alla mia insegnante di pianoforte Ilaria, che mi ha visto crescere e ha saputo darmi preziosi consigli in momenti critici della mia vita. \newline Infine, un grazie ad Alessandro, amico storico dai tempi del Conservatorio, che mi ha incoraggiato a non arrendermi mai di fronte alle difficoltà.}}
% 
%			PREFAZIONE
%

\clearpage
\null
\thispagestyle{empty}
\clearpage

\prefacesection{Abstract}
Il Problema del Commesso Viaggiatore (TSP) rappresenta una delle sfide più interessanti e rilevanti nell'ambito dell'ottimizzazione combinatoria. Originariamente formulato negli anni '30, il TSP richiede di determinare il percorso più breve per visitare un insieme di città esattamente una volta, ritornando infine alla città di partenza. Nonostante la sua apparente semplicità concettuale, il TSP è noto per la sua complessità computazionale e la sua rilevanza pratica in una vasta gamma di settori, inclusi trasporti,  logistica, e progettazione di circuiti.

Il TSP è classificato come un problema NP-hard, il che significa che non esiste un algoritmo efficiente in grado di risolvere tutte le istanze del problema in tempo polinomiale. Di conseguenza, sono state sviluppate numerose euristiche e approcci approssimati per trovare soluzioni accettabili in un tempo ragionevole. Le euristiche sono strategie di ricerca che, pur non garantendo la soluzione ottima, sono in grado di produrre risultati soddisfacenti entro limiti temporali praticabili.

In questa tesi, esploreremo una specifica euristica per il TSP chiamata Furthest Insertion: l'obiettivo principale sarà quello di presentare, analizzare e valutare l'efficacia di questa euristica attraverso run su istanze presenti su TSP-LIB (ci limiteremo solo al TSP euclideo in 2 dimensioni dove i pesi degli archi sono le distanze tra i punti sul piano) e confronti con altre tecniche note.

La scelta di concentrarsi su un'euristica per il TSP è motivata dalla necessità di affrontare problemi di dimensioni reali in contesti applicativi. Mentre le soluzioni esatte sono desiderabili per la loro precisione, spesso richiedono una potenza di calcolo eccessiva per problemi di grandi dimensioni. Le euristiche offrono un compromesso utile tra precisione e efficienza, consentendo di ottenere soluzioni praticabili che possono guidare decisioni reali.

Questa tesi sarà strutturata nel seguente modo: innanzitutto, forniremo una panoramica del TSP e della sua formulazione matematica. Successivamente, esamineremo le principali categorie di approcci risolutivi, concentrandoci in particolare sulle euristiche basate su inserzione. Presenteremo quindi la nuova euristica Furthest Insertion discutendo la sua implementazione e le scelte progettuali adottate. Infine, concluderemo con un'analisi dei risultati ottenuti, identificando i punti di forza e le limitazioni della nuova euristica.

\afterpreface
% 
% 
%			CAPITOLO 1: Introduzione
\chapter{Il Problema del Commesso Viaggiatore}
Il Problema del Commesso Viaggiatore (TSP) è una delle sfide più emblematiche e studiate nell'ambito della ricerca operativa e dell'ottimizzazione combinatoria. Originariamente formulato negli anni '30 da Karl Menger \cite{Menger}, il TSP richiede di determinare il percorso più breve per visitare un insieme di città esattamente una volta, tornando infine alla città di partenza. Nonostante la sua semplice descrizione concettuale, il TSP è noto per la sua complessità computazionale e la sua rilevanza pratica in una vasta gamma di settori.

Le applicazioni del TSP sono diffuse e impattano direttamente su molte attività quotidiane. Ad esempio, nel settore della logistica e della gestione delle catene di distribuzione, il TSP è utilizzato per ottimizzare le rotte dei veicoli di consegna, minimizzando i costi di carburante e il tempo impiegato. In ambito produttivo, il TSP viene impiegato per pianificare i percorsi di ispezione delle fabbriche o per ottimizzare il flusso di lavoro all'interno di un'azienda. Anche nei sistemi di navigazione satellitare e nelle applicazioni GPS, il TSP è alla base dell'ottimizzazione dei percorsi per ridurre il tempo di viaggio.

Storicamente, il TSP ha attratto l'attenzione di numerosi matematici e informatici in quanto è un problema semplice da formulare ma complesso da "risolvere". Il problema è stato formalizzato e reso noto grazie al lavoro di Hassler Whitney nel 1952\footnote[1]{https://www.math.uwaterloo.ca/tsp/uk/history.html} e successivamente nel 1954 da Merrill Flood. La dimostrazione della sua appartenenza alla classe di complessità NP-hard è stata fondamentale per stimolare lo sviluppo di tecniche approssimate e euristiche. Le sfide legate al TSP sono principalmente dovute alla sua natura combinatoria: per n città, il numero di possibili percorsi da valutare cresce in modo esponenziale con n, rendendo impraticabile un'analisi esaustiva per istanze di grandi dimensioni. Questa complessità ha spinto alla ricerca di approcci efficienti, come le euristiche, che non garantiscono la soluzione ottimale ma forniscono soluzioni accettabili in tempi ragionevoli.

\section{Il Problema del commesso viaggiatore}
Il problema del commesso viaggiatore (TSP) può essere sintetizzato molto semplicemente con la seguente domanda: "Date n città, qual è il percorso più breve che inizia e termina con la stessa città?". Il problema quindi presenta le caratteristiche tipiche di un problema su un grafo, dove il grafo è composto da $n$ vertici (le città) e dove gli archi indicano le distanze euclidee tra le città. La formulazione classica del TSP può essere descritta matematicamente attraverso la programmazione intera lineare. La seguente formulazione fa riferimento alla formulazione MTZ (Miller-Tucker-Zemlin) e alla formulazione DFJ (Dantzig-Fulkerson-Johnson) \cite{TSP formulation}.
\section{Formulazione del problema}
\textbf{Dati}: Consideriamo un insieme di $n$ città, ogni città $i$ (per $i = 1, 2, ..., n$) rappresenta un punto nello spazio euclideo, ogni città quindi ha coordinate $(x_i, y_i)$. Definiamo la matrice $c$, dove $c_{ij}$ indica la distanza euclidea tra le due città $i$ e $j$.
\\[1\baselineskip]
\textbf{Variabili}: La variabile $x_{ij}$ è una variabile binaria, quindi: $$ x_{ij} \in \{0, 1\} \qquad \forall i, j = 1, 2, 3, ..., n $$ La variabile $x$ assume valore 0 se l'arco che collega la città $i$ e $j$ non fa parte del path, 1 se ne fa parte.
\\[1\baselineskip] \textbf{Vincoli}: I vincoli sono i seguenti:
\begin{enumerate}
        \item Per ogni città $i$ deve essere presente un solo arco uscente corrispondente nel tour, quindi la somma delle variabili $x_{ij}$ deve essere uguale a 1. $$\sum_{j = 1}^{n} x_{ij} = 1 \qquad \forall i = 1, 2, 3, ..., n$$
        \item Per ogni città $j$ deve essere presente un solo arco entrante corrispondente nel tour, quindi la somma delle variabili $x_{ij}$ deve essere uguale a 1. $$\sum_{i = 1}^{n} x_{ij} = 1 \qquad \forall j = 1, 2, 3, ..., n$$
        \item Non devono essere presenti cicli all'interno del tour, quindi deve valere: $$ \sum_{i \in Q}{\sum_{j \in Q}{x_{ij} \le |Q| - 1}} \qquad \forall Q \subsetneq \{2, 3, ..., n\} $$
\end{enumerate}
\textbf{Funzione Obiettivo}: Si vuole minimizzare il costo totale del tour, quindi:
$$min \sum_{i = 1}^{n} \sum_{j = 1}^{n} c_{ij} x_{ij}$$
La seguente formulazione permette quindi di identificare la soluzione ottima.
\newline \null \newline È stato dimostrato che TSP è un problema NP-hard \cite{TSP NP Completezza}, questo implica che attualmente non sono noti algoritmi con complessità polinomiale che risolvono il problema. Se esistesse un algoritmo con complessità polinomiale che risolve il TSP allora si potrebbe dimostrare che vale P = NP e quindi si risolverebbe uno dei più grandi problemi aperti nella teoria della complessità computazionale. 

\section{Metodi esatti per il TSP}
Esistono vari approcci nella ricerca della soluzione ottima \cite{Analysis of Brute Force}. Un primo approccio "naive" per il problema può essere l'approccio brute-force: consiste nell'enumerare tutti i possibili percorsi e successivamente selezionare il migliore. In questo caso è necessario analizzare $n!$ possibili percorsi (nel peggiore dei casi), per questo motivo tentare di risolvere una istanza TSP con un approccio brute-force implica una complessità computazionale pari a $O(n!)$ e quindi un tempo che risulta rapidamente inaccettabile. Di seguito una tabella che illustra il numero di percorsi da valutare con un approccio basato su ricerca esaustiva al variare del numero n.



\begin{center}
        \begin{tabular}{|c|c|}
                \hline
                \textbf{Numero città} & \textbf{Numero percorsi possibili} \\ % Intestazione in grassetto
                \hline % Linea orizzontale sopra della tabella
                4 & 24 \\
                \hline
                5 & 120 \\
                \hline
                6 & 720 \\
                \hline
                7 & 5,040 \\
                \hline
                8 & 40,320 \\
                \hline
                9 & 362,880 \\
                \hline
                10 & 3,628,800 \\
                \hline
                11 & 39,916,800 \\
                \hline
                12 & 479,001,600 \\
                \hline
                13 & 6,227,020,800 \\
                \hline
                14 & 87,178,291,200 \\
                \hline
                15 & 1,307,674,368,000 \\
                \hline
                16 & 20,922,789,888,000 \\
                \hline
                17 & 355,687,428,096,000 \\
                \hline
                18 & 6,402,373,705,728,000 \\
                \hline
                19 & 121,645,100,408,832,000 \\
                \hline
                20 & 2,432,902,008,176,640,000 \\
                \hline
                21 & 51,090,942,171,709,440,000 \\
                \hline
                22 & 1,124,000,727,777,607,680,000 \\
                \hline
                23 & 25,852,016,738,884,976,640,000 \\
                \hline
                24 & 620,448,401,733,239,439,360,000 \\
                \hline
                25 & 15,511,210,043,330,985,984,000,000 \\
                \hline
        \end{tabular}
        \newline
\end{center}
Si può notare come il numero cresce molto rapidamente, anche con istanze relativamente piccole (ad esempio 20 città). Questo approccio risulta quindi inutilizzabile nei problemi reali dove può essere necessario analizzare istanze con migliaia di città.
\newline \null \newline Esistono altri algoritmi esatti i quali consentono di ridurre il numero di possibili soluzioni (percorsi) da analizzare, ad esempio approcci Branch and Bound \cite{Branch and Bound}. La complessità computazionale nel caso peggiore resta esponenziale in quanto può essere necessario analizzare un numero esponenziale di percorsi e quindi non applicabile su problemi reali.
\newline \null \newline 
Oltre all'approccio brute force, esistono in letteratura diversi algoritmi \textbf{branch-and-bound}\footnote[1]{https://www.math.cmu.edu/~bkell/21257-2014f/tsp.pdf}\footnote[2]{https://apps.dtic.mil/sti/tr/pdf/ADA142318.pdf} che consentono di risolvere in problema in modo più efficiente. L'idea alla base consiste nel suddividere il problema originario in sottoproblemi (più semplici) i quali possono essere a loro volta scomposti in ulteriori sottoproblemi. Il termine "bound" indica il fatto che per ogni sottoproblema viene calcolato il limite inferiore $L_i$ (quindi la soluzione ottima non sarà mai migliore di questo limite inferiore) e si tiene conto della soluzione migliore trovata fino a quel punto $U$: quando $L_i$ è "peggiore" di $U$ allora è possibile scartare a priori l'intero sottoproblema in quanto è già stata trovata una soluzione migliore del limite inferiore del sottoproblema (questo processo prende il nome di "pruning"). Il termine "branch" invece fa riferimento al fatto che i sottoproblemi vengono a loro volta divisi in ulteriori sottoproblemi (come visto prima), l'algoritmo branch-and-bound procede esplorando l'albero dei sottoproblemi generati (detto anche albero branch-and-bound) e scartando i sottoproblemi (pruning) con il criterio visto prima. I vari algoritmi differiscono in base al criterio di branching e di esplorazione dell'albero branch-and-bound. \newline \null \newline
Lo stato dell'arte degli algoritmi esatti per il TSP non sono i generici branch-and-bound ma sono algoritmi \textbf{branch-and-cut}\cite{Branch and Cut}: Branch and Cut è un metodo di ottimizzazione combinatoria simile al branch and bound, ma con alcune differenze fondamentali. Entrambi gli algoritmi mirano a trovare la soluzione ottimale per un problema complesso, dividendolo in sottoproblemi più piccoli e scartando (pruning) i sottoproblemi che in ogni caso non possono portare ad una soluzione parziale migliore di quella già nota. Tuttavia, l'algoritmo Branch and Cut si distingue per l'utilizzo di vincoli di taglio (cutting planes). Di seguito viene illustrato un generico algoritmo branch-and-cut:
\newlist{legal}{enumerate}{10}
\setlist[legal]{label*=\arabic*.}

\begin{tcolorbox}[colframe=black,colback=white,boxrule=0.5pt, sharp corners, breakable]
\begin{legal}
  \item Aggiungi il problema iniziale $ILP$ alla lista dei problemi attivi $L$.
  \item Sia $x^* = null$ e $v^* = -\infty$
  \item Finché $L$ non è vuota:
  \begin{legal}
    \item Seleziona e rimuovi un problema da L
    \item Risolvi il rilassamento continuo di L
    \item Se il problema è inammissibile torna al punto 3 (ciclo while). Altrimenti sia $x$ la soluzione trovata e $v$ il valore della funzione obiettivo.
    \item Se $v \leq v^*$ torna al punto 3
    \item Se $x$ è intero, aggiorna $v^* \leftarrow v$, $x^* \leftarrow x$ e torna al punto 3.
    \item Cerca dei piani di taglio che sono violati da $x$, se sono presenti aggiungili al rilassamento continuo di ILP e torna al punto 3.2
    \item Dividi il problema in sottoproblemi, aggiungi i sottoproblemi alla lista dei problemi attivi $L$, torna al punto 3.
  \end{legal}
  \item Restituisci $x^*$


\end{legal}
\end{tcolorbox}
\hfill \break
Come già detto in precedenza, questo approccio è attualmente lo stato dell'arte per risolvere il TSP all'ottimo. In letteratura esistono varie implementazioni di algoritmi branch-and-cut per il TSP\cite{Branch and Cut Algoritmhs}, sono presenti anche all'interno di risolutori MILP come ad esempio CPLEX. Questo approccio risulta migliore rispetto all'approccio brute-force, ma resta comunque non applicabile su istanze TSP con migliaia di città.

\chapter{Euristiche per il TSP}
Come discusso nel capitolo 2, i metodi esatti consentono di ottenere soluzioni ottime per il problema del TSP, ma il tempo per ottenere queste soluzioni aumenta esponenzialmente all'aumentare del numero di città presenti nell'istanza. Per affrontare il TSP, sono stati sviluppati numerosi approcci euristici, ovvero metodi che, pur non garantendo la soluzione ottimale, offrono soluzioni di buona qualità in tempi ragionevoli. Le euristiche sono fondamentali per applicazioni pratiche dove la rapidità di calcolo è essenziale. In questo capitolo esploreremo diverse tecniche euristiche, come le euristiche costruttive, che costruiscono una soluzione passo dopo passo a partire da una soluzione parziale, vedremo in particolare sulle euristiche basate su inserzione (Furthest Insertion fa parte di questa categoria) e poi le euristiche basate su ricerca locale, ovvero basate su meccanismi che consentono di "migliorare" la soluzione parziale trovata modificando il tour.
\section{Nearest Neighbor} \label{sec:NN}
Nearest Neighbor è probabilmente l'euristica costruttiva più semplice per il TSP: si costruisce il tour selezionando sempre la città più vicina all'ultima appena aggiunta al tour. Appartiene alla categoria delle euristiche costruttive in quanto aggiunge via via nuove città al tour (soluzione parziale) senza modificare il tour costruito fino a quel punto. L'algoritmo è il seguente:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Nearest Neighbor, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
\begin{legal}
  \item Seleziona un nodo arbitrario j, sia l = j e L = $\{1, 2, ..., n\} \setminus \{j\}$.
  \item Finché $L \neq \emptyset$:
  \begin{legal}
    \item Sia $j \in L$ tale che $c_{lj} = min\{c_{li} \  | \  i \in L\}$.
    \item Connetti l a j e rimuovi j da L, quindi $ L = L \setminus \{j\} $.
  \end{legal}
  \item Connetti l al primo nodo (era stato selezionato al punto 1) per formare un tour.
\end{legal}
\end{tcolorbox}
\hfill \break
Nearest Neighbor è una euristica con complessità temporale pari a $O(n^2)$ in quanto per ogni nodo nel tour (quindi n volte) è necessario cercare tra i restanti nodi, qual è il più vicino (al massimo n volte).

\section{Euristiche basate su Inserzione}
Le euristiche basate su inserzione appartengono alla categoria delle euristiche costruttive ma a differenza di Nearest Neighbor la soluzione viene costruita in un modo differente: si inizia da un piccolo tour (che include 2 o 1 città) il quale viene via via esteso includendo i nodi (città) non ancora aggiunti al tour. In questo tipo di euristiche la differenza fondamentale che le distingue sarà il criterio con il quale si aggiungono nuove città al tour e dove queste città devono essere inserite nel tour. Una qualunque euristica basata su inserzione quindi presenta la seguente struttura:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Euristica generica basata su inserzione, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{legal}
  \item Seleziona una città o due città arbitrarie come tour iniziale $T$. Sia $L$ l'insieme delle città che sono fuori dal tour, quindi: $L = \{1, 2, ..., n\} \setminus T$.
  \item Finché $L \neq \emptyset$:
  \begin{legal}
    \item Seleziona un nodo $j \in L$ secondo un certo criterio.
    \item Inserisci $j$ nel tour in una determinata posizione.
    \item Rimuovi $j$ da L, quindi $L = L \setminus \{j\}$.
  \end{legal}
\end{legal}
\end{tcolorbox}
\hfill \break
Questo schema permette di ottenere un ciclo Hamiltoniano e quindi un percorso valido per il problema del TSP. Le varie euristiche andranno a definire un criterio di scelta del nodo j (punto 2.1) e un criterio di scelta della posizione di inserzione (punto 2.2).

\subsection{Nearest Insertion} \label{ssec:NI}
Nearest Insertion seleziona come nodo da inserire nel tour il nodo più vicino ad un qualunque nodo già inserito nel tour e lo inserisce nella posizione che minimizza il costo di inserimento. Di seguito l'algoritmo:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Nearest Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{legal}
    \item Sia $T$ il tour iniziale definito dalla coppia delle città più lontane. Sia $L$ l'insieme delle città fuori dal tour, quindi: $L = \{1, 2, ..., n\} \setminus T$.
    \item Finché $L \neq \emptyset$:
    \begin{legal}
      \item Sia $d_{min}(v)$ la distanza minima tra il nodo $v$ e il tour $T$, ovvero $d_{min}(v) = min\{c_{vt} \  | \ t \in T \}$. Seleziona il nodo $r \not \in T$ in modo da \underline{minimizzare} $d_{min}(r)$.
      \item Determina la posizione ottima di inserzione $(a, b)$ in modo da \underline{minimizzare} il costo di inserimento $c_{ar} + c_{rb} - c_{ab}$, inserisci $r$ tra $(a, b)$
      \item Rimuovi $r$ da L, quindi $L = L \setminus \{r\}$.
    \end{legal}
  \end{legal}
  \end{tcolorbox}
\hfill \break Nearest Insertion ha complessità computazionale pari a $O(n^2)$ in quanto ogni nodo (n iterazioni) deve essere inserito nel modo migliore possibile nel tour (fino a n iterazioni).

\subsection{Cheapest Insertion} \label{ssec:CI}
Cheapest Insertion opera in modo diverso da Nearest Insertion: il criterio di selezione non è più il nodo più vicino al tour, ma diventa il nodo che produce il minor aumento del costo del tour se inserito (quindi minimizza il costo di inserzione). Una volta selezionato, il nodo viene inserito nel modo migliore possibile, quindi minimizzando il costo di inserimento. Di seguito l'algoritmo:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{legal}
    \item Sia $T$ il tour iniziale definito dalla coppia delle città più lontane. Sia $L$ l'insieme delle città fuori dal tour, quindi: $L = \{1, 2, ..., n\} \setminus T$.
    \item Finché $L \neq \emptyset$:
    \begin{legal}
      \item $\forall v \not \in T$, determina il punto di inserzione $P(v)$ (ovvero l'arco $(a, b) \in T$) in modo da \underline{minimizzare} $c_{av} + c_{vb} - c_{ab}$, sia $C(v)$ il costo di inserimento del nodo $v$ nel punto di inserzione trovato.
      \item Tra tutti i nodi fuori dal tour, seleziona il nodo $r$ in modo da \underline{minimizzare} $C(r)$
      \item Inserisci il nodo $r$ nel punto di inserzione $P(r)$ trovato prima
      \item Rimuovi $r$ da L, quindi $L = L \setminus \{r\}$.
    \end{legal}
  \end{legal}
  \end{tcolorbox}
\hfill \break La complessità computazionale di questa euristica verrà discussa nella sezione nel capitolo delle implementazioni in quanto verranno presentate più versioni (con complessità differenti).

\subsection{Farthest Insertion} \label{ssec:FaI}
Farthest Insertion opera in analogo a Nearest Insertion in quanto il criterio di selezione del nodo da inserire è basato sulla distanza dal tour, ma differenza di Nearest Insertion però viene scelto il nodo più lontano dal tour al posto del più vicino. Il passo di inserzione avviene invece allo stesso modo rispetto a Nearest Insertion: viene quindi scelta la posizione che minimizza il costo di inserzione. Vediamo l'algoritmo:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Farthest Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
\begin{legal}
  \item Sia $T$ il tour iniziale definito dalla coppia delle città più lontane. Sia $L$ l'insieme delle città fuori dal tour, quindi: $L = \{1, 2, ..., n\} \setminus T$.
  \item Finché $L \neq \emptyset$:
  \begin{legal}
    \item Sia $d_{min}(v)$ la distanza minima tra il nodo $v$ e il tour $T$, ovvero $d_{min}(v) = min\{c_{vt} \  | \ t \in T \}$. Seleziona il nodo $r \not \in T$ in modo da \underline{massimizzare} $d_{min}(r)$.
    \item Determina la posizione ottima di inserzione $(a, b)$ in modo da \underline{minimizzare} il costo di inserimento $c_{ar} + c_{rb} - c_{ab}$, inserisci $r$ tra $(a, b)$
    \item Rimuovi $r$ da L, quindi $L = L \setminus \{r\}$.
  \end{legal}
\end{legal}
\end{tcolorbox}
\hfill \break Farthest Insertion ha complessità computazionale pari a $O(n^2)$ in modo del tutto analogo a Nearest Insertion.

\subsection{Furthest Insertion} \label{ssec:FuI}
L'obbiettivo della tesi consiste nel proporre un nuovo algoritmo chiamato Furthest Insertion: allo stesso modo in cui Farthest Insertion opera in modo analogo a Nearest Insertion, Furthest Insertion opera in modo analogo a Cheapest Insertion. Il passo di selezione consiste nel selezionare il nodo che massimizza il costo di inserzione, in fase di inserimento però il nodo viene inserito in modo da minimizzare il costo di inserimento. Di seguito l'algoritmo:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
\begin{legal}
  \item Sia $T$ il tour iniziale definito dalla coppia delle città più lontane. Sia $L$ l'insieme delle città fuori dal tour, quindi: $L = \{1, 2, ..., n\} \setminus T$.
  \item Finché $L \neq \emptyset$:
  \begin{legal}
    \item $\forall v \not \in T$, determina il punto di inserzione $P(v)$ (ovvero l'arco $(a, b) \in T$) in modo da \underline{minimizzare} $c_{av} + c_{vb} - c_{ab}$, sia $C(v)$ il costo di inserimento del nodo $v$ nel punto di inserzione trovato.
    \item Tra tutti i nodi fuori dal tour, seleziona il nodo $r$ in modo da \underline{massimizzare} $C(r)$
    \item Inserisci il nodo $r$ nel punto di inserzione $P(r)$ trovato prima
    \item Rimuovi $r$ da L, quindi $L = L \setminus \{r\}$.
  \end{legal}
\end{legal}
\end{tcolorbox}
\hfill \break La complessità computazionale di questa euristica verrà discussa nella sezione nel capitolo delle implementazioni (come per Cheapest Insertion) in quanto verranno presentate più versioni (con complessità differenti).

\subsection{Random Insertion} \label{ssec:RI}
Random Insertion seleziona casualmente il nodo da inserire nel tour, successivamente però sceglie il punto di inserimento in modo da minimizzare il costo di inserimento (esattamente come per Nearest Insertion). Di seguito l'algoritmo:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Random Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
\begin{legal}
  \item Sia $T$ il tour iniziale definito da una città casuale. Sia $L$ l'insieme delle città fuori dal tour, quindi: $L = \{1, 2, ..., n\} \setminus T$.
  \item Finché $L \neq \emptyset$:
  \begin{legal}
    \item Seleziona un nodo $r \in L$ casualmente.
    \item Seleziona l'arco $(i, j)$ in $T$ tale che $c_{ir} + c_{rj} - c_{ij}$ risulti \underline{minimo}.
    \item Inserisci $r$ tra $i$ e $j$.  
    \item Rimuovi $r$ da L, quindi $L = L \setminus \{r\}$.
  \end{legal}
\end{legal}
\end{tcolorbox}
\hfill \break Random Insertion ha complessità computazionale pari a $O(n^2)$ in quanto n volte viene selezionato un nodo casuale, dopodiché è necessario iterare n volte alla ricerca della posizione migliore dove inserire il nodo.

\section{Ricerca Locale}
Le euristiche basate su ricerca locale\cite{Local Search} sono euristiche che implementano un meccanismo che consente di migliorare un tour (anche parziale), il meccanismo può ad esempio scambiare due nodi nel tour (vedremo nel dettaglio una euristica in particolare), rimuovere un nodo e inserirlo in un punto del tour migliore oppure implementare meccanismi più sofisticati.

\subsection{Node Insertion}
Questa euristica permette di migliorare un tour rimuovendo un nodo e inserendolo nel tour nel modo migliore possibile. Di seguito la procedura:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Node Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
\begin{legal}
  \item Sia $T$ il tour (anche parziale).
  \item Ripeti finché il tour $T$ resta invariato:
  \begin{legal}
    \item Per ogni nodo $i = 1, 2, ..., n$: è possibile ridurre la lunghezza del tour rimuovendo il nodo $i$ da una posizione $p_1$ e inserendo il nodo $i$ in un'altra posizione $p_2$? Se si, aggiorna $T$ spostando il nodo $i$ da $p_1$ a $p_2$.
  \end{legal}
\end{legal}
\end{tcolorbox}
\hfill \break
La procedura richiede tempo $O(n^2)$ in quanto per ogni nodo (n volte) è necessario ispezionare il possibile scambio di posizione (n volte).

\subsection{Edge Insertion}
In modo analogo a Node Insertion, questa euristica permette di migliorare un tour rimuovendo un arco (a differenza del nodo di prima) e inserendolo nel tour nel modo migliore possibile. Di seguito la procedura:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Edge Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
\begin{legal}
  \item Sia $T$ il tour (anche parziale).
  \item Ripeti finché il tour $T$ resta invariato:
  \begin{legal}
    \item Per ogni nodo $i = 1, 2, ..., n$, considera l'arco che collega $i$ con il nodo successivo nel tour, sia $(i, j)$ questo arco: è possibile ridurre la lunghezza del tour rimuovendo l'arco $(i, j)$ da una posizione $p_1$ e inserendo $(i, j)$ in un'altra posizione $p_2$? Se si, aggiorna $T$ spostando l'arco da $p_1$ a $p_2$.
  \end{legal}
\end{legal}
\end{tcolorbox}
\hfill \break
La procedura richiede tempo $O(n^2)$ in modo del tutto analogo a Node Insertion.

\subsection{Euristica 2-Opt}
L'algoritmo 2-Opt\cite{2OPT} consente di eliminare due archi e di riconnetterli in un modo diverso, andando quindi a modificare il tour. Questa euristica deriva dall'osservazione empirica per cui due archi che si incrociano possono essere sempre riorganizzati in modo da non incrociarsi e questo produce sempre una riduzione della lunghezza totale del tour. La procedura consente di ridurre la lunghezza del tour riorganizzando una coppia di archi anche quando non si incrociano. Si nota che è sempre possibile ricombinarli in un unico modo diverso. Di seguito la procedura 2-Opt:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=2-Opt, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]

\begin{legal}
  \item Sia $T$ il tour (anche parziale).
  \item Ripeti finché il tour $T$ resta invariato:
  \begin{legal}
    \item Per ogni nodo $i = 1, 2, ..., n$, considera tutti gli scambi 2-Opt possibili con l'arco $(i, j)$ dove $j$ è il nodo successivo ad $i$ nel tour. Se è possibile ridurre la lunghezza del tour applicando lo scambio 2-Opt, aggiorna T.
  \end{legal}
\end{legal}
\end{tcolorbox}
\hfill \break

\subsection{Euristica 3-Opt}
L'euristica 3-Opt è un'estensione dell'euristica vista precedentemente: al posto di eliminare due archi per ricombinarli in modo diverso, in questa euristica sono 3 gli archi che l'euristica rimuove e ricombina in modo diverso. A differenza di 2-Opt sono 8 i modi diversi in cui possono essere ricombinati questi archi\footnote{http://tsp-basics.blogspot.com/2017/03/3-opt-move.html} (includendo anche la configurazione in cui gli archi restano immutati). Vediamo l'algoritmo:

\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=3-Opt, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{legal}
    \item Sia $T$ il tour.
    \item Per ogni nodo $i \in V$, sia $N(i)$ un insieme di nodi.
    \item Ripeti finché il tour $T$ resta invariato:
    \begin{legal}
      \item Per ogni nodo $i = 1, 2, ..., n$: considera tutti gli scambi 3-Opt possibili che includa $i$ e un nodo nell'insieme $N(i)$. Se è possibile ridurre la lunghezza del tour in questo modo, aggiorna T.
    \end{legal}
  \end{legal}
\end{tcolorbox}
\hfill \break
La scelta di ridurre l'insieme dei nodi $V$ a $N(i)$ è necessario in quanto analizzare tutti i possibili scambi che includano 3 nodi implica un tempo $O(n^3)$. L'insieme $N(i)$ può essere generato a partire a partire dal nodo $i$ ad esempio selezionando i 10 nodi più vicini ad $i$.
      
\subsection{Euristica Lin-Kernighan}
L'algoritmo Lin-Kernighan (LK)\cite{LK} è una delle migliori euristiche per risolvere il TSP. Appartiene alla classe degli algoritmi di ricerca locale, che prendono come input un tour (ciclo hamiltoniano) e tentano di migliorarlo cercando nella sua vicinanza un tour più corto, e una volta trovato ripetono il processo da quel nuovo tour, fino a incontrare un minimo locale.
L'algoritmo LK è stato sviluppato da Serge Lin e Brian Kernighan nel 1971 ed è stato dimostrato essere molto efficace per risolvere istanze di TSP di medie e grandi dimensioni. È spesso utilizzato come componente di algoritmi ibridi per il TSP, combinandolo con altre tecniche di ricerca per ottenere risultati ancora migliori. Di seguito una descrizione ad alto livello dell'algoritmo:
\setlist[legal]{label*=\arabic*.}
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Lin-Kernighan, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{legal}
    \item Sia $T$ il tour iniziale, può essere generato casualmente oppure tramite altre euristiche come Nearest Neighbor. Sia $S$ la soluzione migliore fino a questo momento.
    \item Ripeti finché il tour $T$ resta invariato (e quindi è stato trovato un minimo locale):
    \begin{legal}
      \item Applica l'algoritmo k-Opt. Inizialmente $k$ deve essere un valore piccolo (2 o 3), aumenta man mano il valore $k$.
    \end{legal}
    \item Una volta trovato un minimo locale, se è migliore di $S$ allora aggiorna $S$. Torna al punto 1 generando un tour diverso da quello di partenza, oppure l'algoritmo termina e S è la soluzione trovata.
  \end{legal}
\end{tcolorbox}
\hfill \break
L'euristica Lin-Kernighan è considerata una delle migliori euristiche per generare soluzioni ottime o quasi-ottime per il problema del TSP\cite{Helsgaun}.

\lstset{
  language=Python, 
  basicstyle=\ttfamily, 
  keywordstyle=\color{blue}, 
  commentstyle=\color{gray}, 
  stringstyle=\color{red}, 
  showstringspaces=false,
  numbers=left,                 % Aggiunge i numeri di riga a sinistra
  numberstyle=\tiny\color{gray}, % Stile per i numeri di riga
  stepnumber=1,                 % Numerare ogni riga
  numbersep=10pt                % Distanza tra i numeri di riga e il codice
}
\chapter{Implementazione delle euristiche}
Questo capitolo descrive l'implementazione di una classe Python chiamata "TSP" tramite la quale deve essere possibile:
\begin{legal}
  \item Poter generare istanze della classe TSP che rappresenti una particolare istanza del TSP, con la matrice di adiacenza e le altre strutture dati necessarie per la risoluzione del problema
  \item Poter importare i dati di una determinata istanza del TSP (coordinate dei punti, matrice di adiacenza...)
  \item Poter ottenere una soluzione valida per il problema tramite l'invocazione di un metodo che implementa una euristica tra quelle descritte precedentemente
  \item Ottenere i dati relativi alla qualità delle soluzioni e tempi dell'euristica
\end{legal}
Tutto il codice relativo al progetto può essere trovato nel seguente repository \href{https://github.com/cohenasaf/Furthest-insertion}{GitHub}. Per il progetto è stata scelta la libreria TSP-LIB\footnote{http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/} come fonte di istanze per il TSP in quanto in letteratura è ampiamente utilizzata per testare e confrontare algoritmi e euristiche progettate per risolvere il TSP. Ai fini del progetto, è importante sottolineare che ci limitiamo solo al caso di istanze TSP dove i dati forniti indicano le coordinate in due dimensioni (sul piano cartesiano) e i pesi degli archi del grafo sono le distanze tra i punti, quindi: $c_{ab} = \sqrt{(a_x - b_x)^2 + (a_y - b_y)^2}$ Nel progetto, le istanze sono state tutte collocate nella directory "ALL-TSP" dove sono presenti due tipi di file: "NOME.tsp" e "NOME.opt.tour" dove la prima contiene i dati relativi all'istanza chiamata "NOME", mentre la seconda contiene la soluzione ottima sempre per quella istanza. Di seguito la struttura dei file di input:


\lstnewenvironment{myverbatim}[1][]{%
  \lstset{
    basicstyle=\ttfamily,
    frame=tb,
    #1
  }%
}{}

\begin{myverbatim}[title={berlin52.tsp}]
NAME: berlin52
TYPE: TSP
COMMENT: 52 locations in Berlin (Groetschel)
DIMENSION: 52
EDGE_WEIGHT_TYPE: EUC_2D
NODE_COORD_SECTION
1 565.0 575.0
2 25.0 185.0
3 345.0 750.0
4 945.0 685.0
5 845.0 655.0
6 880.0 660.0
7 25.0 230.0
8 525.0 1000.0
9 580.0 1175.0
10 650.0 1130.0
11 1605.0 620.0 
12 1220.0 580.0
13 1465.0 200.0
...
50 595.0 360.0
51 1340.0 725.0
52 1740.0 245.0
EOF
\end{myverbatim}
Dove, come specificato nella documentazione di TSP-LIB\footnote{http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/tsp95.pdf}, gli elementi importanti sono:
\begin{legal}
  \item "NAME": ovvero il nome dell'istanza TSP
  \item "TYPE": ovvero il tipo di problema, nel nostro caso ci limitiamo alle istanze TSP simmetriche (in TSP LIB sono presenti anche istanze ATSP)
  \item "EDGE\_WEIGHT\_TYPE": ovvero il tipo di distanze tra i punti, ai fini del progetto per semplicità mi limito al caso euclideo in due dimensioni
  \item "NODE\_COORD\_SECTION": da questa sezione in poi sono presenti 3 numeri per ogni riga: numero del nodo (città), coordinata x e coordinata y: queste coordinate saranno utili per calcolare le distanze euclidee tra i nodi.
\end{legal}
Per ogni istanza TSP, non solo è presente il relativo file descritto sopra (quindi NOME.tsp), ma anche il file contenente la soluzione ottima "NOME.opt.tour". Di seguito un esempio sempre dall'istanza berlin52:
\begin{myverbatim}[title={berlin52.opt.tsp}]
NAME : berlin52.opt.tour
TYPE : TOUR
DIMENSION : 52
TOUR_SECTION
1
49
32
45
19
41
8
9
10
43
...
30
2
7
42
21
17
3
18
31
22
-1
EOF
\end{myverbatim}
In questa tipologia di file è presente la soluzione in forma di lista dei nodi che formano il tour migliore. È importante notare come i nodi sono numerati da 1 compreso fino a n compreso, nella implementazione della classe (e quindi nelle euristiche) ho deciso di trasporre gli indici nel range [0, n - 1] (compresi) in modo coerente con la numerazione presente nei metodi standard delle liste presenti nel linguaggio Python (quindi ad esempio la città 3 in questo esempio corrisponderà in questa implementazione alla città 2).

\section{Implementazione del costruttore della classe}
Come descritto precedentemente, il costruttore della classe deve consentire di importare i dati relativi ad una istanza specifica del TSP contenuta nella cartella "TSP-ALL", di seguito l'implementazione:
\begin{python}
def __init__(self, name, ignoraOpt=False):
  self.ignoraOpt = ignoraOpt
  self.openTSP(name)
  self.name = name
  self.optimalSolution = soluzioneOttima[name]
\end{python}
Dove: \lstinline!self.openTSP()! è il metodo che effettivamente importa i dati dal file relativo, inoltre sono presenti gli attributi \lstinline!self.name! il quale semplicemente memorizza il nome dell'istanza TSP e l'attributo \lstinline!self.optimalSolution! che memorizza il valore della soluzione ottima dal file "NOME.opt.tour". \hfill \break
Di seguito l'analisi del metodo \lstinline!self.openTSP(name)!:
\begin{python}
def openTSP(self, name):
  f = open(f"ALL-TSP/{name}.tsp")
  self.numCity = -1
  i = 0
  data = False
  self.coord = []
  for line in f:
    if "EOF" in line:
      break
    if line == "":
      continue
    if data:
      line = line.replace("  ", " ")\
              .replace("  ", " ")\
              .replace("\n", "").strip()
      if "." in line.split(" ")[1]:
          self.coord.append([int(float(line.split(" ")[1])), \
                             int(float(line.split(" ")[2]))])
      else:
          self.coord.append([int(line.split(" ")[1]), \
                             int(line.split(" ")[2])])
    if "DIMENSION" in line:
      self.numCity = int(line.split(": ")[1])
    if "NODE_COORD_SECTION" in line:
      data = True
  f.close()
\end{python}
Questa prima parte del metodo permette di aprire il file relativo all'istanza TSP e importa nella lista \lstinline!self.coord! tutte le coppie $(x, y)$ che rappresentano le coordinate cartesiane dei punti.
\begin{python}
def openTSP(self, name):
  ...
  self.adj = [[0 for _ in range(self.numCity)] \
               for _ in range(self.numCity)]
  for i in range(self.numCity):
    for j in range(i):
      if i == j:
        continue
      else:
        self.adj[i][j] = self.adj[j][i] = \
           self.distance(self.coord[i], self.coord[j])
\end{python}
In questa seconda parte del metodo viene calcolata la matrice di adiacenza dell'istanza TSP e memorizzata nell'istanza \lstinline!self.adj! (il metodo \lstinline!self.distance! verrà descritto nella prossima sezione).
\begin{python}
def openTSP(self, name):
  ...
  if not self.ignoraOpt:
      # leggo il persorso ottimale
      f = open(f"ALL-TSP/{name}.opt.tour")
      self.optTour = [-1 for _ in range(self.numCity)]
      self.tour = [-1 for _ in range(self.numCity)]
      data = False
      i = 0
      for line in f:
        if "-1" in line:
          break
        if data:
          self.optTour[i] = int(line) - 1
          i += 1
        if "TOUR_SECTION" in line:
          data = True
      f.close()
  else:
    self.optTour = [-1 for _ in range(self.numCity)]
    self.tour = [-1 for _ in range(self.numCity)]
\end{python}
L'ultima parte del metodo consente di inizializzare le liste  \lstinline!self.optTour! e \lstinline!self.tour! dove la prima contiene la soluzione ottima contenuta nel file "NOME.opt.tour" e la seconda sarà invece utilizzata dalle euristiche costruttive per "costruire" man mano la soluzione.

\section{Implementazione di metodi ausiliari per le euristiche}
In questa sezione analizzo l'implementazione di metodi ausiliari e di supporto. Questi metodi fattorizzano il codice utilizzato frequentemente da diverse euristiche, migliorando la modularità, la leggibilità e la manutenibilità del codice e includono altri metodi utili per la manipolazione di istanze del TSP. \newline
\begin{python}
  def distance(self, a, b):
    return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)
\end{python}
Questo metodo (come visto prima) semplicemente consente di calcolare la distanza euclidea tra due punti a e b. Come descritto precedentemente, ci limitiamo alle istanze del TSP con coordinate in due dimensioni.
\begin{python}
def openRandomTSP(self, n):
  self.name = "random"
  self.numCity = n
  self.adj = [[0 for _ in range(self.numCity)] \
                 for _ in range(self.numCity)]
  for i in range(self.numCity):
    for j in range(i):
      if i == j:
        continue
      else:
        self.adj[i][j] = self.adj[j][i] = random.randint(0, 1000)
\end{python}
Questo metodo consente di generare una istanza casuale del TSP dato come parametro un numero intero n (il numero di città). Dato che il progetto si limita al TSP simmetrico, alla riga 10 si assegna lo stesso valore sia all'arco $(i, j)$ che all'arco $(j, i)$.
\begin{python}
def calculateCost(self):
  self.cost = 0
  for i in range(self.numCity - 1):
    self.cost += self.adj[self.tour[i]][self.tour[i + 1]]
  self.cost += self.adj[self.tour[self.numCity - 1]][self.tour[0]]
\end{python}
Il metodo \lstinline!calculateCost()! consente di assegnare all'attributo \lstinline!self.cost! il costo del tour, che si ottiene sommando i costi degli archi $(i, j)$ per ogni coppia di archi contenuti nel tour. Essendo un ciclo hamiltoniano, alla fine del ciclo for si aggiunge anche il costo per tornare al punto di partenza, quindi il peso dell'arco che collega l'ultima città presente nel tour con la prima.
\begin{python}
def calculateOptimalCost(self):
  self.cost = 0
  for i in range(self.numCity - 1):
    self.cost += self.adj[self.optTour[i]][self.optTour[i + 1]]
  self.cost += self.adj[self.optTour[self.numCity - 1]][self.optTour[0]]
\end{python}
Il metodo \lstinline!calculateOptimalCost()! consente, come nel caso di \lstinline!calculateCost()!, di calcolare il costo del tour, con la differenza che si considera il tour ottimo (attributo \lstinline!self.optTour!) al posto del tour del metodo precedente.
\begin{python}
def verifyTour(self):
  for i in range(self.numCity):
    if not i in self.tour:
      print(f"ERRORE, manca {i}")
      return False
    if self.tour.count(i) != 1:
      print(f"ERRORE, il numero {i} risulta esserci \
             {self.tour.count(i)} volte")
      return False
  return True
\end{python}
Il metodo \lstinline!verifyTour()! consente di testare la correttezza del tour trovato dall'euristica, è quindi pensato per essere verificato (tramite un \lstinline!assert!). Il metodo si limita a verificare che ogni nodo deve essere presente nel tour esattamente una volta sola, il metodo chiaramente non garantisce la presenza di altri errori nell'implementazione dell'euristica. Questo metodo quindi consente di verificare se il tour trovato è almeno una soluzione valida per il problema.

\section{Implementazione delle euristiche}
In questo capitolo, descriveremo l'implementazione delle euristiche per la risoluzione del TSP, in particolare verranno implementate le euristiche costruttive presentate nei capitoli 2.1 e 2.2. Tutte le implementazioni nel linguaggio Python possono essere trovate nel seguente repository \href{https://github.com/cohenasaf/Furthest-insertion}{GitHub}, le implementazioni nelle prossime sezioni saranno discusse in forma di pseudocodice.

\subsection{Nearest Neighbor}
L'euristica \nameref{sec:NN} (NN) costruisce un tour partendo da una città arbitraria, dopodiché sceglie di aggiungere al tour la città più vicina all'ultima città aggiunta al tour. Di seguito viene riportato il codice per questa euristica.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Nearest Neighbor, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $tour = [0]$
    \State $n$ = numero di città
    \While{$len(tour) < n$}
        \State $cost = +\infty$
        \State $j = -1$
        \For{\texttt{$j_2 \not \in tour$}}
          \State $last$ = ultima città nel $tour$
          \If{\texttt{$adj[last][j_2] < cost$}}
            \State $cost$ = adj[last][$j_2$]
            \State $j$ = $j_2$
          \EndIf
        \EndFor
        \State Aggiungi $j$ in fondo al tour
    \EndWhile
    \State Calcola il costo del tour trovato
  \end{algorithmic}
\end{tcolorbox}
Per semplicità ho scelto la prima città (nodo 0) come città iniziale arbitraria, dopodiché finché sono presenti nodi da aggiungere al tour, si cerca un nodo j non ancora visitato che sia il più vicino possibile all'ultimo nodo aggiunto al tour, inoltre alla fine viene calcolato il costo del tour trovato. \newline
Dal punto di vista della complessità temporale, l'implementazione ha tempo pari a $O(n^2)$ in quanto tutte le istruzioni hanno un tempo pari a $O(1)$. Di conseguenza, considerando i due cicli alla riga 3 e 5, la complessità generale è pari a $O(n^2)$.

\subsection{Nearest Insertion}
Nelle prossime sezioni verrà discussa l'implementazione delle euristiche costruttive basate su inserzione, a partire da \nameref{ssec:NI}.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Nearest Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $path = [0, 0]$
    \State $n$ = numero di città
    \State $adj$ = matrice di adiacenza

    \State $minDist = +\infty$
    \For{$i \in \{0, 1, 2, ..., n - 1\}$}
      \For{$j \in \{0, 1, 2, ..., i - 1\}$}
        \If{$adj[i][j] < minDist$}
          \State \texttt{$path[0] = i$}
          \State \texttt{$path[1] = j$}
          \State \texttt{$minDist = adj[i][j]$}
        \EndIf
      \EndFor
    \EndFor
    \State Sia $h$ lo heap
    \For{$i \not \in path$}
      \State $left \gets adj[path[0], i]$
      \State $right \gets adj[path[1], i]$
      \State Aggiungi il record $(min\{left, right\}, i)$ allo heap $h$
    \EndFor
    \State heapify(h)
    \State ...
  \end{algorithmic}
\end{tcolorbox}
Per prima cosa, l'euristica inizializza il tour con la coppia di città più vicine presenti nell'istanza TSP, viene quindi cercato l'arco $(i, j)$ con costo più basso e inizializzato il path (posizione 0 e 1) con questi due nodi.
Successivamente vengono inizializzate le distanze minime e le città più vicine per ogni città non nel percorso. Dato che Nearest Insertion dovrà determinare il nodo fuori dal ciclo con distanza minore rispetto ad un nodo qualunque nel ciclo, si utilizza uno heap (tramite il modulo \lstinline!heapq!) con il quale sarà possibile tenere traccia dei nodi fuori dal ciclo e la loro distanza minima con il tour.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Nearest Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State Ottieni dallo heap il record $r$ con costo minore
      \State Ottieni il nodo $to\_ins$ dal record $r$
      \State Sia $best\_increase \gets +\infty$
      \State Sia $best\_position \gets -1$
      \For{$i \in \{0, 1, 2, ..., len(path) - 1\}$}
        \State $next\_i \gets (i + 1) \mod \text{len(path)}$
        \State $node \gets path[i]$
        \State $next \gets path[next\_i]$
        \State $increase \gets adj[node][to\_ins] + adj[to\_ins][next] - adj[node][next]$
        \If{$increase < best\_increase$}
          \State $best\_increase \gets increase$
          \State $best\_position \gets i + 1$
        \EndIf
      \EndFor
      \State \text{Inserisci $to\_ins$ nel path in posizione $best\_position$}
      \For{$(cost, node) \in h$}
        \Comment{Aggiornamento dello heap}
        \If{$node \not \in path \land adj[to\_ins][node] < cost$}
          \State $(cost, node) \gets (adj[to\_ins][node], node)$
        \EndIf
      \EndFor
      \State heapify(h)
    \EndWhile
    \State Calcola il costo del tour trovato
  \end{algorithmic}
  \end{tcolorbox}
Questo è il ciclo principale dell'euristica: prima di tutto (tramite l'operazione \lstinline!heappop! nel linguaggio Python) viene estratto il nodo \lstinline!to_ins! come nodo candidato da inserire nel ciclo (in quanto ha distanza minima dal tour), successivamente viene effettuata una ricerca nel tour della posizione di inserimento migliore possibile. La posizione migliore deve minimizzare $c_{ir} + c_{rj} - c_{ij}$, quindi la variabile \lstinline!increase! definita alla riga 11.\newline Successivamente (dalla riga 18) viene aggiornato lo heap in quanto alla riga 17 viene modificato il path mentre lo heap fa ancora riferimento al path prima dell'inserimento. L'aggiornamento procede come segue: dato che lo heap contiene, per ogni nodo fuori dal tour, la distanza con il nodo più vicino all'interno del tour (quindi per ogni nodo fuori dal tour, mantiene la distanza minima con il tour), dato che è stato aggiunto un nuovo nodo nel tour, è necessario verificare per ogni elemento nello heap se il nuovo nodo aggiunto rappresenta un caso migliore rispetto a quanto precedentemente memorizzato nello heap, per questo motivo alla riga 19, nel caso in cui la distanza tra il nodo appena aggiunto e il nodo fuori dal path \lstinline!node! è migliore di quanto precedentemente memorizzato nello heap (\lstinline!cost!), allora è necessario aggiornare quel valore nello heap. \newline Successivamente è necessario effettuare l'operazione heapify (nel linguaggio Python: \lstinline!heapq.heapify(h)!) in quanto l'aggiornamento potrebbe aver modificato la struttura dello heap. Alla fine dell'implementazione di Nearest Insertion (come prima) si calcola il costo del path trovato (utilizzando il metodo ausiliario descritto nella sezione precedente \lstinline!calculateCost()!). \newline
La complessità temporale dell'implementazione è $O(n^2)$ dato che sono presenti solo due cicli for che iterano al massimo n volte, tutte le istruzioni nel ciclo interno hanno complessità pari a $O(1)$ e le istruzioni nel ciclo esterno hanno al massimo complessità $O(n)$.

\subsection{Cheapest Insertion: versione 1}
Nelle prossime sezioni discutiamo l'implementazione di \nameref{ssec:CI} che, come abbiamo visto nel secondo capitolo, seleziona i nodi in modo da minimizzare il costo di inserimento (al posto di selezionare i nodi più vicini al tour come visto con nearest insertion). Sono state implementate 3 versioni di questa euristica, iniziamo dalla versione peggiore dal punto di vista della complessità computazionale.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 1, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $n \gets$ numero di città
    \State $adj \gets$ matrice di adiacenza dell'istanza
    \State $path \gets [0, 0]$
    
    \State $minDist \gets +\infty$
    \For{$i \in \{0, 1, ..., n - 1\}$}
      \For{$j \in \{0, 1, ..., i - 1\}$}
        \If{$adj[i][j] < minDist$}
          \State $path[0] \gets i$
          \State $path[1] \gets j$
          \State $minDist \gets adj[i][j]$
        \EndIf
      \EndFor
    \EndFor
    \State ...
  \end{algorithmic}
\end{tcolorbox}
Per prima cosa il path viene inizializzato con la coppia di città più vicine presenti nell'istanza TSP.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 1, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State Sia $ln = []$
      \For{$v \not \in path$}
        \State $record \gets [+\infty, -1, -1, -1]$
        \For{$i \in \{0, 1, ..., len(path) - 1\}$}
          \State $l \gets path[i]$
          \State $r \gets path[(i + 1) \mod len(path)]$
          \State $cost \gets adj[l][v] + adj[v][r] - adj[l][r]$
          \If{$cost < record[0]$}
            \State $record \gets [cost, v, l, r]$
          \EndIf
        \EndFor
        \State Aggiungi $record$ alla lista $ln$
      \EndFor
      \State $[\_, to\_ins, l, r] \gets min(ln)$
      \State Inserisci $to\_ins$ tra $l$ e $r$ nel $path$
    \EndWhile
    \State Calcola il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
Dopodiché inizia il ciclo principale dell'euristica: finché il path non include tutti i nodi, si determina per ogni nodo v fuori dal tour il punto di inserimento ottimo $(i, j)$ nel dal tour in modo da minimizzare il costo di inserimento, quindi si crea per ogni nodo v un record \lstinline![cost, v, l, r]! che contiene le informazioni: costo di inserimento, nodo da inserire \lstinline!v! tra i due nodi \lstinline!l! ed \lstinline!r!. Successivamente dalla lista \lstinline!ln! di record viene selezionato il record con costo minore e si procede all'inserimento. \newline
Questa implementazione di Cheapest Insertion risulta essere molto semplice, ma è inefficiente dal punto di vista della complessità temporale. Infatti sono presenti 3 cicli for che iterano al massimo n volte (riga 2, 4 e 6). Dato che ci sono solo istruzioni con tempo $O(1)$, la complessità totale dell'algoritmo è $O(n^3)$ in quanto sono presenti 3 cicli che iterano fino a n volte. \newline
In particolare l'inefficienza di questa implementazione, consiste nel fatto che ad ogni iterazione vengono ricalcolati i costi di inserimento ottimi per gli stessi nodi, infatti ad ogni iterazione solo un nodo viene inserito nel path, per tutti gli altri nodi fuori dal tour (che sono rimasti fuori dal tour) si ricalcolano esattamente gli stessi costi, con la differenza che un arco è stato rimosso (il punto di inserzione) e sono comparsi due nuovi archi. Per questo motivo nella prossima versione vedremo come memorizzare (e aggiornare) tutte queste informazioni al posto di ricalcolarle ogni volta.

\subsection{Cheapest Insertion: versione 2}
In questa versione di Cheapest Insertion (a differenza della versione precedente) si vuole utilizzare una struttura dati che possa mantenere, per ogni nodo fuori dal tour, il costo e il punto di inserzione ottimi. Per fare questo si può operare in modo analogo a Nearest Insertion, ovvero con uno heap: lo heap andrà a conservare le informazioni dette prima e ci consentirà di ottenere il record con costo minore in modo efficiente, con la differenza, però, che l'aggiornamento dello heap è indubbiamente più complesso: nel caso di Nearest Insertion bastava confrontare il vecchio nodo più vicino con il nuovo nodo aggiunto, in questo caso la struttura del path cambia con un inserimento e quindi, nel caso peggiore, sarà necessario ricalcolare completamente il punto di inserimento ottimo. Vediamo l'implementazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $n \gets$ numero di città
    \State $adj \gets$ matrice di adiacenza dell'istanza
    \State $path \gets [0, 0]$
    
    \State $minDist \gets +\infty$
    \For{$i \in \{0, 1, ..., n - 1\}$}
      \For{$j \in \{0, 1, ..., i - 1\}$}
        \If{$adj[i][j] < minDist$}
          \State $path[0] \gets i$
          \State $path[1] \gets j$
          \State $minDist \gets adj[i][j]$
        \EndIf
      \EndFor
    \EndFor
    \State ...
  \end{algorithmic}
\end{tcolorbox}
La parte iniziale dell'implementazione è identica a Nearest Insertion: viene inizializzato il tour con la coppia di nodi più vicini presenti nell'istanza.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \State Sia $h = []$ lo heap
    \For{$i \not \in path$}
      \State $cost \gets adj[path[0]][i] + adj[i][path[1]] - adj[path[0]][path[1]]$
      \State Aggiungi $(cost, i, path[0], path[1])$ allo heap $h$
    \EndFor
    \State $heapify(h)$
    \State ...
  \end{algorithmic}
\end{tcolorbox}
Come descritto prima, in questa versione viene inizializzato uno heap in modo analogo a Nearest Insertion, ma con una differenza: la chiave associata ad ogni nodo non è più la distanza minima con il tour ma il costo di inserimento (se inserito nel modo migliore possibile). In questo caso il costo di inserimento è semplice da ottenere in quanto nel tour sono presenti solo 2 nodi: dati gli unici due nodi presenti nel tour $a$ e $b$, il costo di inserimento del nodo $i$ sarà $c_{ai} + c_{ib} - c_{ab}$. Lo heap userà come valore chiave il costo (prima variabile della tupla) permettendo quindi di estrarre il nodo \lstinline!i! con costo minore. Nello heap vengono memorizzati anche i due nodi tra i quali dovrebbe avvenire l'inserimento (\lstinline!path[0]! e \lstinline!path[1]!) in quanto sono informazioni che saranno utili nella seconda parte dell'implementazione dell'euristica.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State $(costo, to\_ins, l, r) = heappop(h)$
      \State Sia $best\_pos$ il punto di inserzione $(l, r)$
      \State Inserisci $to\_ins$ nel punto $best\_pos$
      \State ...
    \EndWhile
    \State ...
  \end{algorithmic}
\end{tcolorbox}
Questo è il ciclo for (while) principale dell'euristica: viene selezionato dallo heap il nodo \lstinline!to_ins! e il punto di inserzione \lstinline!r!. Abbiamo visto come nello heap sono presenti le seguenti informazioni: \lstinline!(costo, nodo, l, r)! dove \lstinline!cost! indica il costo di inserzione del nodo \lstinline!nodo! se inserito nel modo migliore possibile e \lstinline!l! e \lstinline!r! sono i due nodi (presenti nel tour) tra i quali è necessario effettuare l'inserzione.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State \dots
      \For{$h_i \in h$}
      \Comment{Aggiornamento dello heap}
        \State $(cost, node, nodeLeft, nodeRight) \gets h_i$
        \State $left \gets path[(best\_pos - 1) \mod len(path)]$
        \State $right \gets path[(best\_pos + 1) \mod len(path)]$
        \State $left\_cost \gets adj[left][node] + adj[node][to\_ins] - adj[left][to\_ins]$
        \State $right\_cost \gets adj[to\_ins][node] + adj[node][right] - adj[to\_ins][right]$
        \If{$node \not \in path \land nodeLeft = left \land nodeRight = right$}
          \State $best\_cost \gets +\infty$
          \State $posL \gets -1; posR \gets -1$
          \For{$i2 \in \{0, 1, ..., len(path) - 1\}$}
            \State $new \gets path[i2]$
            \State $next \gets path[(i2 + 1) \mod len(path)]$
            \State $ins\_cost \gets adj[new][node] + adj[node][next] - adj[new][next]$
            \If{$best\_cost > insertion\_cost$}
              \State $best\_cost, posL, posR \gets insertion\_cost, i2, next\_i$
            \EndIf
          \EndFor
          \State $h_i \gets (best\_cost, node, path[posL], path[posR])$
        \EndIf
        \If{$node \not \in in\_path \land left\_cost < cost$}
          \State $new\_cost \gets left\_cost$
          \State $h_i \gets (new\_cost, node, left, to\_ins)$
        \EndIf
        \If{$node \not \in path \land right\_cost < cost$}
          \State $new\_cost \gets right\_cost$
          \State $h_i \gets (new\_cost, node, to\_ins, right)$
        \EndIf
      \EndFor
      \State heapify(h)
    \EndWhile
    \State Calcola il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
Dalla riga 4 in poi avviene l'aggiornamento dello heap in modo analogo a quanto visto con \nameref{ssec:NI} con una differenza fondamentale: nel caso di Nearest Insertion l'aggiornamento era semplice dato che era solo necessario confrontare il valore memorizzato nello heap con la nuova distanza con il nodo appena aggiunto allo heap, in questo caso invece bisogna tenere in considerazione che, l'inserimento del nuovo nodo nel tour ha generato una modifica del tour (e quindi la cancellazione di un arco e l'inserimento di nuovi due archi) e quindi è necessario verificare che i valori presenti nello heap siano ancora rappresentativi del nuovo tour e, in caso contrario, aggiornare lo heap. Per ogni elemento $h_i$ nello heap $h$, dati i valori \lstinline!node! (nodo da inserire), \lstinline!nodeLeft! e \lstinline!nodeRight! (nodi tra i quali andava inserito \lstinline!node!), i casi da considerare sono:
\begin{legal}
  \item (Riga 10) Nel caso in cui \lstinline!nodeLeft! e \lstinline!nodeRight! corrispondono esattamente ai due nodi tra i quali è stato inserito il nodo \lstinline!to_ins! (nella prima parte del ciclo principale dell'algoritmo), allora è necessario ricalcolare per il nodo \lstinline!node! il costo e il punto di inserimento migliore, in quanto il vecchio arco è stato cancellato. (Riga 10-22).
  \item In ogni altro caso il vecchio arco (tra \lstinline!nodeLeft! e \lstinline!nodeRight!) è rimasto intatto. A questo punto è necessario semplicemente verificare che i due nuovi archi generati dopo l'inserimento possano essere un caso di inserimento con costo minore rispetto a quello presente nello heap (riga 23-30).
\end{legal}
Inoltre è importante notare come l'accesso agli elementi del tour avviene \lstinline!% len(tour)! in quanto il tour è una lista circolare.
Successivamente (come per le altre euristiche), è necessario ripristinare la struttura dello heap tramite \lstinline!heapify(h)! e alla fine calcolare il costo della soluzione trovata. \newline
Questa seconda versione di cheapestInsertion ha complessità temporale $O(n^3)$ come per la prima versione, però con una differenza importante: il terzo ciclo interno (riga 13) viene eseguito solo se è vera la condizione precedente (riga 10), quindi il ricalcolo del punto di inserzione ottimo per il nodo avviene solo se necessario (quando si perde il punto di inserzione ottimo precedente) mentre nella prima versione di questa euristica si ricalcola il punto di inserzione ottimo per ogni nodo ad ogni iterazione. Vedremo nel prossimo capitolo come le prestazioni (tempi) di questa seconda implementazione è sempre migliore della prima.

\subsection{Cheapest Insertion versione 2 Approssimata}
Una successiva possibile ottimizzazione può derivare dalla seguente osservazione: una volta che il punto di inserzione ottimo si perde perché è stato già inserito un nodo proprio in quel punto, può essere ragionevole pensare che il nuovo punto di inserimento ottimo sia vicino a quello appena perso. Per verificare (o smentire) questa ipotesi si può molto semplicemente contare il numero di volte che il nuovo punto di inserzione ottimo è "vicino" al precedente punto di inserzione e con "vicino" si può intendere ad esempio che sia uno dei due nuovi archi creati dall'inserzione precedente. Quindi dal punto di vista dell'implementazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $conteggio \gets 0$
    \State $tot \gets 0$
    \State ...
    \While{$len(path) < n$}
      \State \dots
      \For{$h_i \in h$}
        \State ...
        \If{$node \not \in path \land nodeLeft = left \land nodeRight = right$}
          \State $best\_cost \gets +\infty$
          \State $posL \gets -1; posR \gets -1$
          \For{$i2 \in \{0, 1, ..., len(path) - 1\}$}
            \State $new \gets path[i2]$
            \State $next \gets path[(i2 + 1) \mod len(path)]$
            \State $ins\_cost \gets adj[new][node] + adj[node][next] - adj[new][next]$
            \If{$best\_cost > insertion\_cost$}
              \State $best\_cost, posL, posR \gets insertion\_cost, i2, next\_i$
            \EndIf
          \EndFor
          \State $h_i \gets (best\_cost, node, path[posL], path[posR])$
          \If{$|posR - best\_pos| \leq 2$}
            \State $conteggio \gets conteggio + 1$
          \EndIf
            \State $tot \gets tot + 1$
          \EndIf
          \State ...
        \EndFor
        \State ...
      \EndWhile
      \State ...
  \end{algorithmic}
\end{tcolorbox}
Possiamo notare le seguenti modifiche alla versione 2 presentata nella sezione precedente: aggiungiamo (alla riga 1 e 2) due variabili \lstinline!tot! e \lstinline!conteggio! che permetteranno di contare quante volte nuovo valore trovato si trovi "nelle vicinanze" del punto di inserzione del nodo precedente. Per questo motivo alla riga 20 e 21 è presente la condizione descritta prima: in questo caso stiamo considerando un punto di inserzione "vicino" al punto di inserzione del nodo precedente se dista al massimo 2 posizioni all'interno del path. Possiamo quindi ottenere una percentuale tramite il rapporto $conteggio/tot$ e i risultati sono:
I risultati trovati sono (scegliendo alcune istanze dalla libreria TSP-LIB):
\begin{myverbatim}
berlin52 -> 0.9963
kroB200 -> 0.9997
rat575 -> 0.9990
vm1084 -> 0.9992
u1817 -> 0.9980
\end{myverbatim}
Quindi è possibile affermare (con una probabilità molto alta, superiore al 99\%) che l'arco con costo di inserzione minimo si trova nelle vicinanze del precedente arco con costo di inserzione minimo. Dopo questa osservazione è possibile applicare questa semplice modifica all'implementazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 2 Approssimata, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State \dots
      \For{$h_i \in h$}
        \State ...
        \If{$node \not \in path \land nodeLeft = left \land nodeRight = right$}
          \State $best\_cost \gets +\infty$
          \State $posL \gets -1; posR \gets -1$
          \For{$i2 \in \{best\_pos - k, best\_pos - k + 1, ..., best\_pos + k\}$}
            \State $new \gets path[i2]$
            \State $next \gets path[(i2 + 1) \mod len(path)]$
            \State $ins\_cost \gets adj[new][node] + adj[node][next] - adj[new][next]$
            \If{$best\_cost > insertion\_cost$}
              \State $best\_cost, posL, posR \gets insertion\_cost, i2, next\_i$
            \EndIf
          \EndFor
          \State $h_i \gets (best\_cost, node, path[posL], path[posR])$
        \EndIf
        \State ...
      \EndFor
      \State ...
    \EndWhile
    \State ...
  \end{algorithmic}
\end{tcolorbox}
La modifica (riga 9) consiste nel ridurre lo spazio di ricerca da tutto il path al solo intorno (di raggio k) attorno al punto \lstinline!best_pos!, k è un parametro del metodo che può assumere valore 2, 3 o anche 4 ad esempio. Questa modifica rappresenta una ottimizzazione rilevante soprattutto nel caso di istanze molto grandi (con migliaia o decine di migliaia di città): in quel caso al posto di iterare su tutto il path, si itera solo per le 3-4 città attorno al punto di inserzione ottimo precedente, tuttavia è importante sottolineare che la complessità di questa implementazione è $O(n^2)$ ma non garantisce la scelta del punto ottimo di inserzione: infatti è sempre presente una probabilità $\leq 1$ nella quale il punto di inserzione ottimo per un determinato nodo sia fuori dallo spazio di ricerca. Per questo motivo questa versione "approssimata" di Cheapest Insertion opera in modo molto simile alla versione 2 (in termini di qualità delle soluzioni) ma non allo stesso modo.

\subsection{Cheapest Insertion: versione 3}
In questa ultima versione di Cheapest Insertion si riesce (finalmente) a ridurre la complessità computazionale rispetto alle due versioni precedenti. Nella versione 2 abbiamo visto una implementazione con un heap che tiene traccia per ogni nodo del punto di inserzione ottimo, inoltre abbiamo visto come questa informazione non sia sufficiente nel caso in cui il punto di inserzione ottimo si perda dopo l'inserimento di un altro nodo. L'idea per questa ultima implementazione quindi sarebbe quella di tenere traccia per ogni nodo anche di altre posizioni di inserzione sub-ottime che possono subentrare nel caso appunto la posizione ottima si perda. Per implementare questa idea quindi è necessario avere più heap (uno associato ad ogni nodo fuori dallo heap) ed è necessario avere una struttura dati che consenta di associare, ad ogni arco presente nel tour, tutti i record che fanno riferimento a quell'arco in modo da poterli eliminare nel caso in cui, appunto, l'arco scompare dal path. Per fare questo ho deciso di utilizzare un dizionario che associa coppie di interi (archi) a liste di record. Vediamo l'implementazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $n \gets$ numero di città
    \State $adj \gets$ matrice di adiacenza dell'istanza
    \State $path \gets [0, 0]$
    
    \State $minDist \gets +\infty$
    \For{$i \in \{0, 1, ..., n - 1\}$}
      \For{$j \in \{0, 1, ..., i - 1\}$}
        \If{$adj[i][j] < minDist$}
          \State $path[0] \gets i$
          \State $path[1] \gets j$
          \State $minDist \gets adj[i][j]$
        \EndIf
      \EndFor
    \EndFor
    \State ...
  \end{algorithmic}
\end{tcolorbox}
Come per le euristiche precedenti, inizialmente si seleziona la coppia di città più vicine per inizializzare il tour. Il parametro \lstinline!m! aggiunto (riga 1) verrà descritto nelle prossime pagine.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ..
    \State Sia $h$ lo heap principale
    \State sia $d$ il dizionario che associa $(i, j)$ a liste di record che puntano a $(i, j)$
    \State Si inizializzano $d[(path[0], path[1])]$ e $d[(path[1], path[0])]$ con due liste vuote
    \For{$i \not \in path$}
      \State $cost \gets adj[path[0]][i] + adj[i][path[1]] - adj[path[0]][path[1]]$
      \State $h\_i \gets [cost, i, path[0], path[1]]$
      \State $h\_i2 \gets [cost, i, path[1], path[0]]$
      \State Aggiungi $[h\_i, h\_i2]$ allo heap $h$
      \State Aggiungi $h\_i$ a $d[(path[0], path[1])]$
      \State Aggiungi $h\_i2$ a $d[(path[1], path[0])]$
    \EndFor
    \State heapify(h)
  \end{algorithmic}
\end{tcolorbox}
Successivamente si inizializzano le due strutture dati principali dell'euristica: lo heap principale (che andrà a contenere i vari heap dei nodi fuori dal path) e il dizionario descritto precedentemente che viene inizializzato con la coppia di città città più vicine. Dopodiché per ogni nodo fuori dal path, si inizializza lo heap specifico di ogni nodo (riga 7-8) che contiene inizialmente gli unici due inserimenti possibili: tra l'arco \lstinline!path[0]! - \lstinline!path[1]! oppure tra l'arco \lstinline!path[1]! - \lstinline!path[0]!, inoltre si aggiungono i nuovi record alla lista degli archi \lstinline!path[0]! - \lstinline!path[1]! e \lstinline!path[1]! - \lstinline!path[0]! del dizionario. Alla fine, si procede con la costruzione dello heap tramite istruzione \lstinline!heapify(h)!. Importante specificare che in questa fase non è necessaria l'istruzione \lstinline!heapify(h_i)! per ogni piccolo heap dei nodi fuori dal tour, in quanto per ora sono solo presenti due record con lo stesso costo.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State \dots
    \While{$len(path) < n$}
      \State $h\_i \gets heappop(h)$
      \State $(costo, to\_ins, l, r) \gets heappop(h\_i)$
      \State Sia $best\_pos$ posizione $(l, r)$
      \State Inserisci $to\_ins$ nella posizione $best\_pos$
      \For{$p \in d[(l, r)]$}
        \State Cancella $p$ assegnando costo $+\infty$
      \EndFor
      \State ...
    \EndWhile
    \State ...
  \end{algorithmic}
\end{tcolorbox}
Dalla riga 2 inizia il ciclo principale dell'euristica: si seleziona dallo heap principale \lstinline!h! lo heap specifico di un determinato nodo fuori dal tour \lstinline!h_i!, dallo heap piccolo si estrae il record \lstinline!(costo, to_ins, l, r)! nel quale sono presenti le informazioni utili per l'inserimento: il nodo da inserire \lstinline!to_ins! e i due nodi \lstinline!l! ed \lstinline!r! tra i quali va inserito il nodo, mentre il primo elemento (il costo) può essere scartato e quindi poi si procede all'inserimento del nodo tra \lstinline!l! ed \lstinline!r!. Importante notare come il modulo \lstinline!heapq! effettua dei confronti tra record andando a usare come chiave l'elemento in prima posizione nel record, nel nostro caso il costo. Inoltre nel caso dello heap principale \lstinline!h!, l'elemento chiave diventa il costo presente nel primo record di ogni lista, quindi le liste di record vengono confrontate considerando solo il costo del primo record di ogni lista. A questo punto è necessario cancellare tutti i record che puntano all'arco $(l, r)$: per ottenere questo risultato ho deciso di assegnare costo infinito ai record associati a quell'arco: in questo modo si evita che possano essere estratti (alla riga 8) record con archi che non sono più presenti nel path.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \While{$len(path) < n$}
      \State \dots
      \For{$hp \in h$}
        \State $node \gets hp[0][1]$
        \State $sx \gets path[(best\_pos - 1) \mod len(path)]$
        \Comment{Inserimento a sinistra}
        \State $dx \gets path[best\_pos]$
        \State $newCost \gets adj[sx][node] + adj[node][dx] - adj[sx][dx]$
        \State $l \gets [newCost, node, sx, dx]$
        \If{$(sx, dx) \not \in d$}:
        \State d[(sx, dx)] = [l]
        \Else{}:
        \State Aggiungi $l$ a $d[(sx, dx)]$
        \EndIf
        \State Aggiungi $l$ ad $hp$
        
        \State $sx \gets path[best\_pos]$
        \Comment{Inserimento a destra}
        \State $dx \gets path[(best\_pos + 1) \mod len(path)]$
        \State $newCost \gets adj[sx][node] + adj[node][dx] - adj[sx][dx]$
        \State $l \gets [newCost, node, sx, dx]$
        \If{$(sx, dx) \not \in d$}:
            \State d[(sx, dx)] = [l]
        \Else{}:
            \State Aggiungi $l$ a $d[(sx, dx)]$
        \EndIf
        \State Aggiungi $l$ ad $hp$
        \State heapify(hp)
        \Comment{$O(log(n))$}
      \EndFor
      \State heapify(h)
    \EndWhile
    \State Determina il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
Una volta inserito il nodo nel tour, si procede con l'aggiornamento del dizionario e degli heap associati ai nodi fuori dal tour, ovvero: per ogni heap "piccolo" presente nello heap principale, si procede aggiungendo (allo heap piccolo) i due nuovi record relativi ai due nuovi archi creati: nelle righe 5-14 si procede con l'arco a sinistra e con le righe 15-24 con l'arco a destra. In più si aggiornano i dizionari con i nuovi archi creati aggiungendo i riferimenti ai nuovi record (righe 12 e 22).
In conclusione si procede con il ripristino della struttura dello heap piccolo (riga 25). \newline In questa versione, finalmente riusciamo a ridurre la complessità temporale dell'algoritmo a $O(n^2 \cdot log(n))$ in quanto tutte le istruzioni hanno complessità temporale $O(1)$ eccetto per i due cicli for che iterano fino a n volte ed eccetto l'istruzione $heapify(hp)$ che, per ogni heap del nodo, opera ricostruendo la struttura dello heap.

\subsection{Cheapest Insertion versione 3 Approssimata}
Abbiamo visto, nella sezione precedente, come siamo riusciti a ridurre la complessità temporale a $O(n^2 \cdot log(n))$, però è possibile operare con una ulteriore ottimizzazione: è possibile limitare la dimensione degli heap piccoli ad una dimensione $m < n$: per ogni istanza, deve essere presente una soglia $m_{ott} < n$ sotto la quale non si può più garantire la scelta del nodo che minimizza il costo di inserimento (e del punto di inserzione). Per ogni istanza, quindi, è necessario trovare questo valore $m_{ott}$ a partire da $n$ scendendo finché la qualità trovata resta invariata. Di seguito l'algoritmo con la variazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 3 Approssimata, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \While{$len(path) < n$}
      \State \dots
      \For{$hp \in h$}
        \State Aggiornamento dello heap ...
      \EndFor
      \For{$hp \in h$}
        \State limita la dimensione di $hp$ al valore $m$
      \EndFor
      \State heapify(h)
    \EndWhile
    \State Determina il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
Possiamo notare come alla riga 6, dopo aver aggiornato gli heap piccoli aggiungendo nuovi record e dopo aver ricostituito la condizione di heap per ogni $hp$, si mantengono solo i primi $m$ record (alla riga 7). La complessità risulta quindi essere $O(n^2 \cdot log(m))$, vedremo nel prossimo capitolo i risultati di questa versione, sopratutto i tempi rispetto alla versione 3 $O(n^2 \cdot log(n))$.

\subsection{Farthest Insertion}
In questa sezione discutiamo l'implementazione di \nameref{ssec:FaI}. L'implementazione di questa euristica condivide molto del codice già discusso nella implementazione di Nearest Insertion, sono però presenti delle piccole modifiche che consentono di selezionare il nodo più lontano al posto del nodo più vicino (al tour), di seguito l'implementazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Farthest Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $n \gets$ numero di città
    \State $adj \gets$ matrice di adiacenza dell'istanza
    \State $path \gets [0, 0]$
    
    \State $maxDist \gets 0$
    \For{$i \in \{0, 1, ..., n - 1\}$}
      \For{$j \in \{0, 1, ..., i - 1\}$}
        \If{$adj[i][j] > maxDist$}
          \State $path[0] \gets i$
          \State $path[1] \gets j$
          \State $maxDist \gets adj[i][j]$
        \EndIf
      \EndFor
    \EndFor
    \State Sia $h$ lo heap
    \For{$i \not \in path$}
      \State $left \gets adj[path[0], i]$
      \State $right \gets adj[path[1], i]$
      \State Aggiungi $(min\{left, right\}, i)$ allo heap $h$
    \EndFor
    \State heapify\_max(h)
    \State ...
  \end{algorithmic}
  \end{tcolorbox}
L'euristica inizializza il tour con la coppia di città più lontane (a differenza della coppia di città più vicine nel caso di Nearest Insertion) presenti nell'istanza TSP, viene quindi cercato l'arco $(i, j)$ con costo più alto e inizializzato il path (posizione 0 e 1) con questi due nodi.
In modo del tutto analogo a Nearest Insertion, viene inizializzato uno heap il quale conterrà il costo di inserimento se il nodo viene inserito nel modo migliore possibile. Dato che il metodo heappop all'interno del modulo \lstinline!heapq! restituisce l'elemento più piccolo (quindi il nostro heap h opera come un min-heap) e dato che per Farthest Insertion è necessario prelevare il nodo con il costo maggiore (e non minore), per questo motivo alla riga 20 è presente l'istruzione $heapify_max$ la quale costruisce un max-heap (a differenza di $heapify$ che costruisce un min-heap), in questo modo potremo selezionare il nodo che massimizza la minima distanza dal tour.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Farthest Insertion, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State \dots
    \While{$len(path) < n$}
      \State $(\_, to\_ins) \gets heappop(h)$
      \State $best\_increase \gets +\infty$
      \State $best\_position \gets (-1, -1)$
    \For{$i \in \{0, 1, ..., len(path) - 1\}$}
      \State $next\_i \gets (i + 1) \mod len(path)$
      \State $node \gets path[i]$
      \State $next \gets path[next\_i]$
      \State $increase = adj[node, to\_ins] + adj[to\_ins, next] - adj[node, next]$
      \If{$increase < best\_increase$}
        \State $best\_increase \gets increase$
        \State $best\_position \gets i + 1$
      \EndIf
    \EndFor
    \State Inserisci $to\_ins$ in posizione $best\_position$
    \For{$h_i \in h$}
      \State $(cost, node) \gets h_i$
      \If{$node \not \in in\_path \land adj[to\_ins, node] < cost$}
        \State $h_i \gets (adj[to\_ins, node], node)$
      \EndIf
    \EndFor
    \State heapify\_max(h)
  \EndWhile
  \State Ottieni il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
Questo è il ciclo principale dell'euristica: il codice è totalmente identico a quanto visto con nearest insertion, con la piccola (ma importantissima) differenza alla riga 23 dove è presente l'istruzione "heapify\_max" che consente di generare un max-heap e quindi alla riga 3 di prelevare il nodo che massimizza la distanza (ovvero il primo valore di ogni record nello heap). \newline
La complessità temporale di questa implementazione è la stessa di Nearest Insertion, quindi $O(n^2)$.

\subsection{Furthest Insertion: versione 1}
Nelle seguenti sezioni discutiamo l'implementazione di \nameref{ssec:FuI} ovvero la nuova euristica proposta in questa tesi. Nella precedente sezione abbiamo visto come farthest insertion condivide molto del codice di nearest insertion con delle piccole modifiche che consentono di selezionare il nodo più lontano al posto del nodo più vicino. Allo stesso modo furthest insertion condivide molto del codice di cheapest insertion, verranno di seguito presentate le piccole (ma importanti) modifiche rispetto alle tre versioni di Cheapest Insertion che consentono di selezionare il nodo che, se inserito in modo da minimizzare il costo di inserzione, ha costo di inserimento massimo. Come nel caso di Cheapest Insertion, vediamo le tre versioni in ordine dalla peggiore alla migliore dal punto di vista della complessità computazionale:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 1, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $n \gets$ numero di città
    \State $adj \gets$ matrice di adiacenza dell'istanza
    \State $path \gets [0, 0]$
    
    \State $maxDist \gets 0$
    \For{$i \in \{0, 1, ..., n - 1\}$}
      \For{$j \in \{0, 1, ..., i - 1\}$}
        \If{$adj[i][j] > maxDist$}
          \State $path[0] \gets i$
          \State $path[1] \gets j$
          \State $maxDist \gets adj[i][j]$
        \EndIf
      \EndFor
    \EndFor
  \end{algorithmic}
\end{tcolorbox}
Come per visto nell'implementazione di Farthest Insertion, si seleziona la coppia di nodi più lontana per inizializzare il path. 
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 1, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \While{$len(path) < n$}
      \State $ln \gets []$
      \For{$v \not \in path$}
        \State $record \gets [+\infty]$
        \For{$i \in \{0, 1, 2, ..., len(path) - 1\}$}
          \State $l \gets path[i]$
          \State $r = path[(i + 1) \mod len(path)]$
          \State $cost \gets adj[l][v] + adj[v][r] - adj[l][r]$
          \If{$cost < record[0]$}:
            \State $record \gets [cost, v, l, r]$
          \EndIf
          \EndFor
          \State Aggiungi $record$ ad $ln$
      \EndFor
      \State $[\_, to\_ins, l, r] \gets max(ln)$
      \State Inserisci $to\_ins$ nel punto di inserzione $(l, r)$
    \EndWhile               
    \State Calcola il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
Successivamente (ciclo principale del'euristica) in modo analogo alla versione di Cheapest Insertion versione 1, si genera una lista di record che contiene, per ogni nodo \lstinline|v| fuori dal tour, il punto di inserzione ottimo \lstinline!(l, r)! in modo da minimizzare l'inserimento, però è presente una differenza importante: alla riga 15 si procede selezionando il massimo ($[\_, to\_ins, l, r] \gets max(ln)$) ovvero il record che massimizza il miglior costo di inserimento. Successivamente si procede all'inserimento come per Cheapest Insertion. \newline
Come descritto nei capitoli precedenti, la complessità temporale di questo algoritmo è $O(n^3)$ e non è presente nessun tipo di ottimizzazione: ad ogni iterazione è necessario ricalcolare completamente il punto di inserzione ottimo.

\subsection{Furthest Insertion: versione 2}
Come nel caso della versione 2 di Cheapest Insertion, si può evitare di ricalcolare totalmente il punto di inserzione ottimo con uno heap, con una differenza importante: lo heap deve operare come un max-heap e non come un min-heap, ovvero deve selezionare ad ogni iterazione il nodo con costo di inserzione massimo (se inserito nel modo migliore possibile). Vediamo l'implementazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $n \gets$ numero di città
    \State $adj \gets$ matrice di adiacenza dell'istanza
    \State $path \gets [0, 0]$
    
    \State $maxDis \gets 0$
    \For{$i \in \{0, 1, ..., n - 1\}$}
      \For{$j \in \{0, 1, ..., i - 1\}$}
        \If{$adj[i][j] > maxDist$}
          \State $path[0] \gets i$
          \State $path[1] \gets j$
          \State $maxDist \gets adj[i][j]$
        \EndIf
      \EndFor
    \EndFor
    \State ...
  \end{algorithmic}
\end{tcolorbox}
Inizialmente l'euristica determina la coppia di nodi più lontani (come visto prima).
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \State Sia $h = []$ lo heap
    \For{$i \not \in path$}
      \State $cost \gets adj[path[0]][i] + adj[i][path[1]] - adj[path[0]][path[1]]$
      \State Aggiungi $(cost, i, path[0], path[1])$ allo heap $h$
    \EndFor
    \State $max\_heapify(h)$
  \end{algorithmic}
\end{tcolorbox}
Esattamente come nel caso di farthest insertion, viene inizializzato il max-heap con i costi e successivamente (riga 7) è presente l'istruzione $max\_heapify$ che (come visto per Farthest Insertion) consente di generare un max-heap e quindi in prima posizione sarà presente il nodo (e il punto di inserimento) che massimizza il costo di inserzione.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State $(costo, to\_ins, l, r) = heappop(h)$
      \State Sia $best\_pos$ il punto di inserzione $(l, r)$
      \State Inserisci $to\_ins$ nel punto $best\_pos$
      \State ...
    \EndWhile
  \end{algorithmic}
\end{tcolorbox}
Questo è il ciclo principale dell'euristica: viene selezionato dallo heap il nodo \lstinline!to_ins! ovvero il nodo che massimizza il costo di inserimento se inserito nel modo migliore possibile.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State \dots
      \For{$h_i \in h$}
      \Comment{Aggiornamento dello heap $h$}
        \State $(cost, node, nodeLeft, nodeRight) \gets h_i$
        \State $left \gets path[(best\_pos - 1) \mod len(path)]$
        \State $right \gets path[(best\_pos + 1) \mod len(path)]$
        \State $left\_cost \gets adj[left][node] + adj[node][to\_ins] - adj[left][to\_ins]$
        \State $right\_cost \gets adj[to\_ins][node] + adj[node][right] - adj[to\_ins][right]$
        \If{$node \not \in path \land nodeLeft = left \land nodeRight = right$}
          \State $best\_cost \gets +\infty$
          \State $posL \gets -1; posR \gets -1$
          \For{$i2 \in \{0, 1, ..., len(path) - 1\}$}
            \State $new \gets path[i2]$
            \State $next \gets path[(i2 + 1) \mod len(path)]$
            \State $ins\_cost \gets adj[new][node] + adj[node][next] - adj[new][next]$
            \If{$best\_cost > insertion\_cost$}
              \State $best\_cost, posL, posR \gets insertion\_cost, i2, next\_i$
            \EndIf
          \EndFor
          \State $h_i \gets (best\_cost, node, path[posL], path[posR])$
        \EndIf
        \If{$node \not \in in\_path \land left\_cost < cost$}
          \State $new\_cost \gets left\_cost$
          \State $h_i \gets (new\_cost, node, left, to\_ins)$
        \EndIf
        \If{$node \not \in path \land right\_cost < cost$}
          \State $new\_cost \gets right\_cost$
          \State $h_i \gets (new\_cost, node, to\_ins, right)$
        \EndIf
      \EndFor
      \State max\_heapify(h)
    \EndWhile
    \State Calcola il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
Dalla riga 4 in poi avviene l'aggiornamento dello heap in modo del tutto analogo a cheapest insertion, con la sola modifica alla riga 32: l'istruzione $heapify$ diventa $max\_heapify$ in modo da mantenere in prima posizione hello heap, ad ogni iterazione, il nodo che massimizza il costo di inserzione (se inserito nel modo migliore possibile).\newline
Le considerazioni riguardo la complessità temporale di questa implementazioni sono le stesse della versione 2 di Cheapest Insertion, ovvero mantiene un tempo pari a $O(n^3)$ nel peggiore dei casi, ma nella pratica ha delle prestazioni (tempi) sempre migliori rispetto alla prima versione in quanto il terzo ciclo interno viene eseguito solo in certi casi e quindi non sempre.

\subsection{Furthest Insertion versione 2 Approssimata}
Come visto con Cheapest Insertion, è possibile ridurre lo spazio di ricerca (riga 14 dell'ultimo box) all'intorno $(best\_pos - k, best\_pos + k)$ dove k rappresenta il raggio dell'intorno. La versione risultante è la seguente:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 2 Approssimata, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State \dots
      \For{$h_i \in h$}
        \State ...
        \If{$node \not \in path \land nodeLeft = left \land nodeRight = right$}
          \State $best\_cost \gets +\infty$
          \State $posL \gets -1; posR \gets -1$
          \For{$i2 \in \{best\_pos - k, best\_pos - k + 1, ..., best\_pos + k\}$}
            \State $new \gets path[i2]$
            \State $next \gets path[(i2 + 1) \mod len(path)]$
            \State $ins\_cost \gets adj[new][node] + adj[node][next] - adj[new][next]$
            \If{$best\_cost > ins\_cost$}
              \State $best\_cost, posL, posR \gets ins\_cost, i2, next\_i$
            \EndIf
          \EndFor
          \State $h_i \gets (best\_cost, node, path[posL], path[posR])$
        \EndIf
        \State ...
      \EndFor
      \State ...
    \EndWhile
    \State ...
  \end{algorithmic}
\end{tcolorbox}
La modifica risulta essere la stessa vista per Cheapest Insertion versione 2 approssimata (riga 9).

\subsection{Furthest Insertion: versione 3}
Esattamente come nel caso della versione 3 di Cheapest Insertion, è possibile implementare una versione di Furthest Insertion con complessità minore di $O(n^3)$. Questa implementazione quindi condivide molto del codice visto nella versione 3 di Cheapest Insertion, con la differenza che lo heap principale deve operare come un max-heap (in modo da selezionare il nodo con costo maggiore) mentre gli heap interni devono continuare ad operare come dei min-heap in modo da selezionare, per un determinato nodo fuori dal tour, il punto di inserimento che minimizza il costo di inserzione. Vediamo l'implementazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State $n \gets$ numero di città
    \State $adj \gets$ matrice di adiacenza dell'istanza
    \State $path \gets [0, 0]$
    
    \State $maxDist \gets 0$
    \For{$i \in \{0, 1, ..., n - 1\}$}
      \For{$j \in \{0, 1, ..., i - 1\}$}
        \If{$adj[i][j] > maxDist$}
          \State $path[0] \gets i$
          \State $path[1] \gets j$
          \State $maxDist \gets adj[i][j]$
        \EndIf
      \EndFor
    \EndFor
    \State ...
  \end{algorithmic}
\end{tcolorbox}
Come per le altre versioni, si inizializza il path con la coppia delle città più lontane.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Cheapest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ..
    \State Sia $h$ lo heap principale
    \State sia $d$ il dizionario che associa $(i, j)$ a liste di record che puntano a $(i, j)$
    \State Si inizializzano $d[(path[0], path[1])]$ e $d[(path[1], path[0])]$ con due liste vuote
    \For{$i \not \in path$}
      \State $cost \gets adj[path[0]][i] + adj[i][path[1]] - adj[path[0]][path[1]]$
      \State $h\_i \gets [cost, i, path[0], path[1]]$
      \State $h\_i2 \gets [cost, i, path[1], path[0]]$
      \State Aggiungi $[h\_i, h\_i2]$ allo heap $h$
      \State Aggiungi $h\_i$ a $d[(path[0], path[1])]$
      \State Aggiungi $h\_i2$ a $d[(path[1], path[0])]$
    \EndFor
    \State max\_heapify(h)
  \end{algorithmic}
\end{tcolorbox}
Successivamente si inizializzano le due strutture dati fondamentali dell'implementazione, ovvero lo heap principale e il dizionario (come per la versione 3 di Cheapest Insertion), l'unica differenza consiste nell'istruzione $max\_heapify$ al posto di $heapify$ alla riga 13 in modo da ottenere un max-heap per lo heap principale. 
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State \dots
    \While{$len(path) < n$}
      \State $h\_i \gets heappop(h)$
      \State $(costo, to\_ins, l, r) \gets heappop(h\_i)$
      \State Sia $best\_pos$ posizione $(l, r)$
      \State Inserisci $to\_ins$ nella posizione $best\_pos$
      \For{$p \in d[(l, r)]$}
        \State $p[0] \gets +\infty$
        \Comment{Cancellazione del record p}
      \EndFor
      \State ...
    \EndWhile
  \end{algorithmic}
\end{tcolorbox}
Dalla terza riga inizia il ciclo principale dell'euristica: dallo heap principale \lstinline!h! (max-heap) si preleva lo heap associato al massimo costo di inserimento, dallo heap del nodo \lstinline!h\_i! si preleva il record con costo di inserimento minimo (all'interno dello heap piccolo), dopodiché si procede con l'inserimento del nodo nel path, inoltre si procede alla cancellazione dei record che puntano all'arco appena eliminato assegnando costo infinito. Importante sottolineare come le due istruzioni $heappop$ alla riga 3 e 4 operano in modo diverso: il primo preleva lo heap piccolo con costo massimo, il secondo preleva il record con costo minimo.
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State \dots
      \For{$hp \in h$}
        \State $node \gets hp[0][1]$
        \State $sx \gets path[(best\_pos - 1) \mod len(path)]$
        \Comment{Inserimento a sinistra}
        \State $dx \gets path[best\_pos]$
        \State $newCost \gets adj[sx][node] + adj[node][dx] - adj[sx][dx]$
        \State $l \gets [newCost, node, sx, dx]$
        \If{$(sx, dx) \not \in d$}:
        \State d[(sx, dx)] = [l]
        \Else{}:
        \State Aggiungi $l$ a $d[(sx, dx)]$
        \EndIf
        \State Aggiungi $l$ ad $hp$
        
        \State $sx \gets path[best\_pos]$
        \Comment{Inserimento a destra}
        \State $dx \gets path[(best\_pos + 1) \mod len(path)]$
        \State $newCost \gets adj[sx][node] + adj[node][dx] - adj[sx][dx]$
        \State $l \gets [newCost, node, sx, dx]$
        \If{$(sx, dx) \not \in d$}:
            \State d[(sx, dx)] = [l]
        \Else{}:
            \State Aggiungi $l$ a $d[(sx, dx)]$
        \EndIf
        \State Aggiungi $l$ ad $hp$
        \State heapify(hp)
        \Comment{$O(log(n))$}
      \EndFor
      \State max\_heapify(h)
    \EndWhile
    \State Determina il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
La restante parte dell'implementazione è analoga alla versione 3 di Cheapest Insertion, con la differenza che è necessario mantenere il max-heap in modo che selezioni il record con costo di inserimento massimo (e non minimo) e gli heap interni come min-heap. Per mantenere questa proprietà, molto semplicemente si opera con l'istruzione $heapify$ alla riga 26 dopo ogni aggiornamento dello heap piccolo e poi con l'istruzione $max\_heapify$ alla riga 28 per mantenere lo heap principale un max-heap. \newline
Da un punto di vista della complessità temporale, l'algoritmo ha un tempo (nel caso peggiore) pari a $O(n^2 \cdot log(n))$ come già visto per la descrizione di Cheapest Insertion versione 3.

\subsection{Furthest Insertion versione 3 Approssimata}
Anche in questo caso (come per la versione 3 approssimata di Cheapest Insertion), possiamo limitare la dimensione degli heap piccoli:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Furthest Insertion Versione 3, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State ...
    \While{$len(path) < n$}
      \State \dots
      \For{$hp \in h$}
        \State \dots
      \EndFor
      \For{$hp \in h$}
        \State limita la dimensione di $hp$ al valore $m$
      \EndFor
      \State max\_heapify(h)
      \Comment{$O(log(m))$}
    \EndWhile
    \State Determina il costo del path trovato
  \end{algorithmic}
\end{tcolorbox}
Limitando la dimensione degli heap piccoli a $m < n$ la complessità generale migliora da $O(n^2 \cdot log(n))$ a $O(n^2 \cdot log(m))$, è importante determinare la $m$ minima in modo da comunque garantire (per una determinata istanza) la selezione del nodo con costo di inserzione massimo (se inserito nel modo migliore possibile).

\subsection{Random Insertion}
In questo capitolo verrà discussa l'implementazione di \nameref{ssec:RI}. Vedremo come di fatto è molto più semplice rispetto alle implementazioni viste prima in quanto bisogna:
\begin{legal}
  \item Selezionare casualmente un nodo fuori dal tour
  \item Inserirlo nel modo migliore possibile
\end{legal}
Di seguito il metodo:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Random Insertion Versione 1, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State Sia $n$ il numero di città presenti nell'istanza
    \State Sia $dist$ la matrice di adiacenza
    \State Si inizializza $path \gets [0]$
    \State Sia $notInPath$ una lista contenente gli altri nodi, quindi $[1, 2, ..., n - 1]$
    \State Applica il metodo \lstinline!shuffle! per mescolare casualmente $notInPath$
  \end{algorithmic}
\end{tcolorbox}
L'euristica inizialmente sceglie come primo nodo arbitrario il nodo 0. Successivamente 
per quanto riguarda il primo punto discusso prima (scegliere casualmente il nodo da inserire), sono presenti due strade possibili:
\begin{legal}
  \item Inizializzare una lista \lstinline![1, 2, ..., n]! tramite il metodo \lstinline!range(1 ,n)! e poi nel ciclo principale dell'euristica selezionare casualmente un nodo dalla lista per poi rimuoverlo tramite il metodo \lstinline!notInPath.remove(i)! (dove i è l'elemento da rimuovere) o tramite istruzione \lstinline!del notInPath[pos]! dove pos è la posizione dell'elemento da rimuovere.
  \item Inizializzare una lista \lstinline![1, 2, ..., n]! tramite il metodo \lstinline!range(1 ,n)!, mescolare la lista tramite metodo \lstinline!random.shuffle(notInPath)! e poi procedere con la selezione del nodo casuale tramite \lstinline!notInPath.pop()!.
\end{legal}
Da un punto di vista della complessità temporale, ho scelto la seconda strada in quanto rimuovere un elemento dalla lista (tramite \lstinline!del! oppure \lstinline!remove!) richiede un tempo $O(n)$ (dove n è la lunghezza della lista), mentre il metodo \lstinline!l.pop()! ha complessità temporale $O(1)$\footnote{https://wiki.python.org/moin/TimeComplexity}. Per questo motivo (contando il ciclo principale dell'euristica) il primo metodo richiederebbe in un tempo $O(n^2)$ (n iterazioni per il ciclo principale, O(n) per l'istruzione \lstinline!remove! o \lstinline!del!), mentre il secondo metodo richiederebbe un tempo $O(n)$ (n iterazioni per il ciclo principale e poi solo $O(1)$ per il metodo \lstinline!notInPath.pop()!). Inoltre l'implementazione del metodo \lstinline!random.shuffle()!\footnote{https://hg.python.org/cpython/file/2e8b28dbc395/Lib/random.py alla riga 276} utilizza il l'algoritmo Fisher-Yates shuffle\cite{knuthart}, ovvero un algoritmo che opera in tempo $O(n)$. Di conseguenza la restante parte dell'implementazione è:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Random Insertion Versione 1, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
\begin{algorithmic}[1]
  \State \dots
  \While{$len(path) < n$}
    \State $to\_ins \gets notInPath.pop()$
    \State $best\_increase \gets +\infty$
    \State $best\_position \gets (-1, -1)$
    \For{$i \in \{0, 1, ..., len(path) - 1\}$}
      \State $next\_i \gets (i + 1) \mod len(path)$
      \State $node \gets path[i]$
      \State $next \gets path[next\_i]$
      \State $increase \gets dist[node, to\_ins] + dist[to\_ins, next] - dist[node, next]$
      \If{$increase < best\_increase$}
        \State $best\_increase \gets increase$
        \State $best\_position \gets next\_i$
      \EndIf
    \EndFor
    \State Inserisci $to\_ins$ nella posizione $best\_position$
  \EndWhile
  \State Determina il costo del path trovato
\end{algorithmic}
\end{tcolorbox}
Come discusso precedentemente, il ciclo principale dell'algoritmo procede estraendo il nodo casuale (riga 4), successivamente viene effettuata una ricerca della posizione migliore dove inserire il nodo casuale. Voglio sottolineare come questo metodo non sia "completamente casuale", ma solo la parte della selezione del nodo fuori dal tuor è casuale, mentre la parte relativa all'inserimento all'interno del tour opera scegliendo il punto di inserzione che minimizzi il costo di inserimento. \newline
In conclusione sono presenti le stesse istruzioni viste nelle altre euristiche (calcolo del costo).

\subsection{Random Insertion: versione 2}
Per completezza, ho implementato anche una versione di random insertion dove non solo la scelta del nodo da inserire nel tour avviene casualmente, ma anche il punto di inserzione viene scelto casualmente, di seguito l'implementazione:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Random Insertion Versione 2, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State Sia $notInTour$ la lista di tutti i nodi $\{0, 1, ..., n - 1\}$
    \State Applica il metodo $shuffle$ a $notInTour$
    \State Inizializza il $tour$ con $[notIntour.pop()]$
    \For{$i \in notInTour$}
      \State Inserisci $i$ in un punto casuale nel $tour$
    \EndFor
    \State Calcola il costo del path trovato
  \end{algorithmic}
  \end{tcolorbox}
In questa versione dell'algoritmo, la prima parte è identica alla prima versione di random insertion (scelta casuale del nodo tramite una lista \lstinline!notInTour! mescolata casualmente), mentre la seconda (ciclo principale) effettua un inserimento nel tour tramite istruzione \lstinline|tour.insert(pos)| dove la posizione (pos) viene scelta casualmente tramite il metodo \lstinline|random.randint()|.

\subsection{Euristiche con inizializzazione casuale}
Le euristiche viste nelle sezioni precedenti prevedono come inizializzazione del tour la coppia delle città più vicine per cheapest insertion e nearest insertion mentre prevedono la coppia delle città più lontane per farthest insertion e furthest insertion. Nel successivo capitolo verrà analizzata anche la robustezza delle euristiche implementate rispetto all'inizializzazione, per questo motivo nella classe TSP sono presenti 4 varianti delle euristiche descritte nelle sezioni precedenti dove le due città iniziali vengono scelte casualmente. Le 4 euristiche prendono il nome di NOMEInsertionRandomStart dove al posto di "NOME" è presente il nome dell'euristica (nearest, cheapest ...). Di seguito la descrizione della parte diversa:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Nearest Insertion Random Start, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State Sia $n$ il numero di città presenti nell'istanza
    \State Sia $dist$ la matrice di adiacenza
    \State Inizializza $path$ con $[a, b] : a, b \in \{0, 1, ..., n - 1\} \land a \neq b$
    \State ...
  \end{algorithmic}
  \end{tcolorbox}
In questo caso è stato selezionato nearestInsertionRandomStart a titolo di esempio (nelle altre 4 implementazioni il codice è lo stesso): vengono scelte due città casuali come prime due città nel tour. Successivamente (righe 5-6) è necessario ripetere il processo nel caso in cui le due città scelte corrispondano alla stessa città. Una volta selezionati i primi due nodi casualmente, l'euristica può continuare normalmente come visto prima.
Lo stesso criterio è stato applicato anche per nearestNeighbor, di seguito solo la prima istruzione dell'implementazione di nearestNeighborRandomStart:
\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, title=Nearest Neighbor Random Start, coltitle=black, fonttitle=\bfseries, colbacktitle=white, breakable]
  \begin{algorithmic}[1]
    \State Sia $n$ il numero di città presenti nell'istanza
    \State Sia $dist$ la matrice di adiacenza
    \State Inizializza $path$ con una città casuale $a \in \{0, 1, ..., n - 1\}$
    \State ...
  \end{algorithmic}
  \end{tcolorbox}
In questa variante (come per le euristiche basate su inserzione) il tour viene inizializzato con una città casuale (da 0 a $n - 1$), inoltre viene aggiunto nodo casuale scelto nella riga precedente al set \lstinline!visited! (mentre nell'implementazione di nearest nearestNeighbor viene aggiunto direttamente 0). La restante parte dell'implementazione è completamente uguale all'implementazione di nearestNeighbor.

\chapter{Analisi dei risultati}
In questo capitolo si analizzano i risultati trovati dalle euristiche precedentemente implementate, in particolare si analizzano:
\begin{legal}
  \item {\bf Qualità delle soluzioni}: ovvero il costo totale del tour trovato in rapporto con la soluzione ottima, dove le soluzioni ottime sono state ottenute sempre da TSP-LIB\footnote{http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/STSP.html}. Quindi ad esempio una qualità trovata pari a "1.2" indica che si discosta del 20\% rispetto all'ottimo. Una euristica viene valutata di qualità migliore rispetto ad un'altra se si ottiene un valore più vicino a 1 (e quindi all'ottimo).
  \item {\bf Tempi}: ovvero quanti secondi sono stati necessari per trovare la soluzione.
\end{legal}
Per completezza, di seguito sono indicate le caratteristiche tecniche dell'elaboratore con il quale sono stati ottenuti i risultati (solo i dettagli tecnici rilevanti):
\begin{myverbatim}
CPU:    Intel(R) Core(TM) i5-10400F CPU (12) @ 2.90GHz
GPU:    NVIDIA GeForce GTX 1650
RAM:    32 GB DDR4
SO:     Arch Linux x86_64
Kernel: Linux 6.9.7-arch1-1
\end{myverbatim}
Tutti i tempi trovati in questo capitolo fanno riferimento esclusivamente al tempo relativo all'euristica analizzata, tutti i tempi precedenti (importazione dell'istanza TSP, calcolo della matrice di adiacenza...) sono esclusi dal tempo finale. Per ottenere solo i tempi relativi all'euristica, tutti i test seguono questa struttura:
\begin{python}
def testEuristic(name, euristic):
  st = time.time()
  euristic()
  et = time.time()
  t.calculateCost()
  assert t.verifyTour()
  return (t.cost / t.optimalSolution, et - st)
\end{python}
Dove l'euristica passata come parametro è l'euristica da analizzare (qualità e tempi), viene considerato il solo il tempo d'inizio dell'euristica e di fine per calcolare il tempo finale. I risultati sono ottenuti come coppie $(quality, time)$ dalle quali si ottengono i dati per i successivi grafici. Inoltre si verifica per ogni istanza e per ogni euristica che la soluzione trovata sia almeno valida (assert).

\section{Confronto versioni Cheapest Insertion}
Prima di confrontare le varie euristiche tra di loro, ho deciso di confrontare le varie versioni di Cheapest Insertion in modo da ottenere la versione che complessivamente (in media) ottiene i tempi migliori, la stessa varrà per Furthest Insertion (la prossima sezione). \newline
\subsection{Dimensione ottimale degli heap per la versione 3} 
Per prima cosa è necessario determinare la dimensione minima del parametro m (ovvero la dimensione oltre la quale si perdono punti di inserimento sub-ottimi che ad un certo punto dell'esecuzione dell'euristica diventavano il punto di inserimento ottimo) in modo da ottenere la stessa soluzione rispetto a dimensioni maggiori ma migliorando i tempi in quanto si riduce il parametro m della complessità $O(n^2 \cdot log(m))$. Per determinare la dimensione minima, si può scrivere un semplice script che itera l'esecuzione dell'euristica fino a quando la qualità della soluzione inizia a cambiare, ad esempio:
\begin{myverbatim}
m = 8 -> cost: 474.00, quality: 1.1127, time: 0.003978s
m = 7 -> cost: 474.00, quality: 1.1127, time: 0.003748s
m = 6 -> cost: 474.00, quality: 1.1127, time: 0.003632s
m = 5 -> cost: 474.00, quality: 1.1127, time: 0.003647s
m = 4 -> cost: 474.00, quality: 1.1127, time: 0.003484s
m = 3 -> cost: 474.00, quality: 1.1127, time: 0.003652s
m = 2 -> cost: 474.00, quality: 1.1127, time: 0.003275s
m = 1 -> cost: 474.00, quality: 1.1127, time: 0.003155s
Cheapest eil51 -> 1
\end{myverbatim}
In questo esempio possiamo notare come al variare della dimensione degli heap \lstinline!m!, la quality trovata resta la stessa, addirittura fino a dimensione 1. Questo indica che non è realmente necessario, per ogni nodo fuori dal tour, uno heap ma (per questa specifica istanza) basta un solo record che indica la posizione ottima. Si può notare come il time si riduce al ridursi di \lstinline!m! in modo coerente con la complessità temporale. \newline
Andando a considerare altre istanze possiamo trovare che la dimensione minima di \lstinline!m! resta bassa (attorno ad 1 o 3), ad esempio:
\begin{myverbatim}
pr144
m = 8 -> cost: 73220.17, quality: 1.2508, time: 0.032970s
m = 7 -> cost: 73220.17, quality: 1.2508, time: 0.045978s
m = 6 -> cost: 73220.17, quality: 1.2508, time: 0.031315s
m = 5 -> cost: 73220.17, quality: 1.2508, time: 0.030179s
m = 4 -> cost: 73220.17, quality: 1.2508, time: 0.029308s
m = 3 -> cost: 73220.17, quality: 1.2508, time: 0.029944s
m = 2 -> cost: 73413.09, quality: 1.2541, time: 0.040187s
Cheapest pr144 -> 3
\end{myverbatim}
In questo secondo esempio invece possiamo notare come la soluzione trovata con parametro \lstinline!m = 2! cambia rispetto ai casi $m > 2$, per questo motivo la dimensione minima del parametro è 3. È possibile determinare il parametro m minimo per ogni istanza in modo semplice con uno script, di seguito la rappresentazione tramite grafico:\newline
\includegraphics[width=1\textwidth]{../Grafici/1.png} \
In questo grafico a barre possiamo notare per ogni istanza (asse x, ordinati in base alla dimensione n) il parametro minimo m. Possiamo notare come tendenzialmente assume valore 1 per le istanze piccole (con alcune eccezioni) e invece ad un valore pari a 3 per le istanze grandi (con migliaia di città).

\subsection{Analisi dei tempi delle versioni di Cheapest Insertion}
Una volta determinato il parametro minimo (e quindi il tempo minimo per quella versione), possiamo confrontare i tempi delle varie versioni per ogni istanza: \newline
\includegraphics[width=1\textwidth]{../Grafici/2.png} \
In questo grafico possiamo notare come indubbiamente i tempi della prima versione $O(n^3)$ sono sempre peggiori delle altre versioni (compresa la seconda versione $O(n^3)$ anche se hanno stessa complessità temporale), allo stesso modo i tempi della seconda versione $O(n^3)$ è peggiore della terza versione $O(n^2 \cdot log(m))$ (dove la m utilizzata per ottenere questi risultati è la m minima trovata precedentemente). Da un punto di vista dei tempi l'implementazione migliore risulta essere la versione 2 approssimata, ovvero con complessità pari a $O(n^2)$, ma questa versione, come descritto nella sezione dedicata, non garantisce ad ogni iterazione di selezionare il nodo e il punto di inserzione ottimi, per questo motivo, dal punto di vista dei tempi, consideriamo la terza versione la migliore (ovvero la versione con più heap per ogni nodo fuori tour). Inoltre, aggiungo il fatto che il grafico mostra i tempi in scala logaritmica per una migliore leggibilità (i tempi variano da millesimi di secondo a centinaia di secondi).
\subsection{Analisi delle qualità delle versioni di Cheapest Insertion}
Dal punto di vista delle qualità trovate, le 3 versioni trovano in quasi tutti i casi lo stesso path e di conseguenza la stessa soluzione. Esistono però dei casi molto particolari nei quali, anche se l'algoritmo implementato è lo stesso, i path finali trovati sono diversi. Questo avviene perché ad ogni iterazione, l'implementazione deve determinare il nodo che, se inserito nel modo migliore possibile, ha costo di inserzione minimo, dopodiché procede ad inserire il nodo nel punto di inserimento ottimo. Il problema sorge nella misura in cui ad un determinato punto dell'esecuzione dell'euristica, sono presenti 2 punti di inserimento ottimi $(a_1, b_1)$ e $(a_2, b_2)$ per il nodo da inserire $v$ tali che $c_{a1v} + c_{vb1} - c_{a1b1} = c_{a2v} + c_{vb2} - c_{a2b2}$. Pertanto, in presenza di un caso del genere, la scelta del punto di inserzione tra $(a_1, b_1)$ e $(a_2, b_2)$ è arbitrario, ma alla fine producono due path completamente diversi (con costi diversi). Per questo motivo il grafico sulle qualità delle soluzioni trovate dalle versioni è il seguente: \newline
\includegraphics[width=1\textwidth]{../Grafici/3.png} \
In questo grafico possiamo notare come in quasi tutti i casi, le quattro varianti trovano gli stessi risultati, con alcune eccezioni: la versione approssimata non garantisce di selezionare il punto di inserzione ottimo (in quanto cerca solo "localmente" come visto in precedenza) e quindi è logico che trovi in vari contesti path molto diversi, invece le versioni 2 e 3 a volte possono portare a soluzioni completamente diverse, anche se implementano correttamente l'euristica. Dati i risultati (sostanzialmente equivalenti) e date le grandi differenze di tempo viste nella sezione precedente, possiamo affermare che la terza versione sia complessivamente la migliore e sarà scelta come confronto con le altre euristiche. Citiamo solo un caso come esempio: eseguendo la versione 2 e la versione 3 sull'istanza pr124 si ottengono costi diversi (pari a 66232.56 per la versione ottimizzata e 66466.35 per la versione non ottimizzata), dopo una attenta analisi si scopre che ad un certo punto, la versione ottimizzata decide di inserire il nodo 23 nell'arco (22, 21), mentre la versione non ottimizzata decide di inserire lo stesso nodo (23) tra l'arco (38, 22) e, in entrambi i casi, il costo di inserimento è 1000 ed è il costo di inserimento minimo. Con questi dati possiamo affermare che entrambi gli algoritmi operano correttamente e che la scelta di quale punti di inserzione scegliere (se entrambi ottimi) è arbitraria ed in entrambi i casi l'euristica è stata implementata correttamente (anche se si ottengono alla fine path diversi).

\section{Confronto versioni Furthest Insertion}
In modo analogo alla sezione precedente, analizziamo prima di tutto la dimensione minima degli heap dei nodi fuori dal tour (versione 3) e procediamo poi a confrontare tempi e qualità.
\subsection{Dimensione ottimale degli heap per la versione 3 }
\includegraphics[width=1\textwidth]{../Grafici/4.png} \
Da questo grafico possiamo notare una importante differenza: la dimensione minima del parametro m è maggiore nel caso di Furthest Insertion rispetto a Cheapest Insertion: necessita sempre di un parametro m almeno pari a 3 fino alla dimensione massima pari a 6-7 (ci siamo limitati per questioni di tempo alle prime 50 istanze presenti su TSP-LIB), in un solo caso è necessario $m=10$. Per ogni istanza, l'implementazione ottimizzata userà la dimensione m minima trovata nelle successive analisi (come visto prima per Cheapest Insertion).
\subsection{Analisi dei tempi delle versioni di Furthest Insertion}
Di seguito il grafico dei tempi delle versioni di Furthest Insertion: \newline
\includegraphics[width=1\textwidth]{../Grafici/5.png} \
Anche in questo caso è stato deciso di mostrare i dati con una scala logaritmica. Possiamo notare come la prima versione ($O(n^3)$ senza ottimizzazioni) risulta essere molto peggiore (in termini di tempo) rispetto alle altre versioni, inoltre questa differenza risulta essere più marcata rispetto a Cheapest Insertion versione 1. La versione 2 approssimata risulta essere la migliore in quanto ha complessità pari a $O(n^2)$ ma non la consideriamo in quanto non garantisce la scelta del nodo con costo di inserimento massimo (se inserito nel modo migliore possibile). Invece per quanto riguarda il confronto tra la versione 2 $O(n^3)$ e la versione ottimizzata $O(n^2 \cdot log(m))$ risulta essere migliore la prima (anche se ottengono tempi molto simili). Questo risultato può essere spiegabile con la seguente osservazione: effettuando un conteggio delle volte in cui la condizione if risulta vera (la condizione if che porta al terzo ciclo interno che rende la seconda versione $O(n^3)$) ci si rende conto che è vera in poche circostanze in contrasto con Cheapest Insertion versione 2 dove risultava vera molte volte, ad esempio:
\begin{myverbatim}
u1817: Cheapest -> 147917; Furthest -> 18993
u2319: Cheapest -> 112479; Furthest -> 25774
\end{myverbatim}
Questi sono i conteggi relativi al numero di volte che la condizione if (prima del terzo ciclo interno) risulti vera con la stessa istanza. Possiamo notare che nel caso di Furthest risulta essere un numero molto minore rispetto a Cheapest, per questo possiamo notare un miglioramento notevole dei tempi con l'ottimizzazione (dalla versione 2 alla 3 di Cheapest Insertion) mentre non notiamo questo miglioramento nel caso di Furthest Insertion.
\subsection{Analisi delle qualità delle versioni di Furthest Insertion}
Di seguito il grafico relativo alle qualità trovate dalle versioni di Furthest Insertion: \newline
\includegraphics[width=1\textwidth]{../Grafici/6.png} \
In questo caso possiamo notare che la versione approssimata trova soluzioni molto diverse rispetto alle altre 3 euristiche in quanto non garantisce la scelta del punto di inserzione con costo di inserimento minimo. Inoltre notiamo la stessa differenza nelle altre euristiche discussa nella sezione precedente: la versione 1, 2 e 3 implementano correttamente l'euristica ma presentano risultati diversi in quanto sono presenti più punti di inserzione ottimo per lo stesso nodo. Di seguito lo stesso grafico senza la versione approssimata: \newline
\includegraphics[width=1\textwidth]{../Grafici/6_2.png} \
In questo grafico possiamo notare come sono limitati i casi in cui le soluzioni trovate dalle 3 versioni sono diverse. \newline
Possiamo quindi concludere che la versione migliore (soprattutto dal punto di vista dei tempi in quanto le qualità delle soluzioni sostanzialmente si equivalgono) è la versione 2 e non la versione 3, ovvero la versione con un solo heap e non la versione con più heap per ogni nodo fuori dal tour.

\section{Confronto tempi e qualità delle euristiche}
In questo capitolo andremo a confrontare i risultati delle euristiche implementate nel capitolo precedente. Le euristiche che considereremo sono quindi:
\begin{legal}
  \item Nearest Neighbor
  \item Nearest Insertion
  \item Cheapest Insertion versione 3
  \item Farthest Insertion
  \item Furthest Insertion versione 2
\end{legal}
A differenza della sezione precedente, oltre ai tempi in questo caso le qualità trovate sono fondamentali nella valutazione delle euristiche. Ci limitiamo alla versione 3 di Cheapest Insertion (la versione approssimata, quindi con una opportuna $m_{ott} < n$ ottimale per ogni istanza) e Furthest Insertion versione 2 come visto nella sezione precedente. In questo caso analizzeremo qualità e tempi, ma sopratutto valuteremo anche le prestazioni su istanze enormi ($> 10000$ città). L'analisi delle versioni di randomInsertion e la robustezza delle euristiche riguardo l'inizializzazione sarà analizzata nei prossimi capitoli. Analizzeremo anche Nearest Neighbor anche se non è una euristica basata su inserzione per completezza.
\subsection{Analisi delle qualità delle euristiche}
Di seguito il grafico che mostra le qualità trovate dalle euristiche (asse y) per le prime 50 istanze presenti in TSP-LIB ordinate per numero di città (asse x): \newline
\includegraphics[width=1\textwidth]{../Grafici/7.png} \
Premettendo che si vuole una qualità più vicina possibile a 1 (quindi un costo totale più vicino possibile a quello ottimo), da questo grafico possiamo notare più cose: innanzitutto Nearest Neighbor risulta essere in molti contesti l'euristica peggiore, ad esempio per quanto riguarda le prime 10 città (a sinistra) risulta essere molto in alto rispetto alle altre soluzioni trovate (quindi ha trovato soluzioni peggiori), inoltre vale lo stesso discorso per molte istanze grandi verso le migliaia di città (a destra nel grafico). Il discorso analogo ma invertito vale per Furthest Insertion (ovvero l'euristica nuova proposta in questa tesi): possiamo notare come le qualità trovate sia per istanze piccole che grandi siano tra le migliori, ma anche le qualità trovate da Farthest Insertion risultano ottimo, possiamo verificare con una media dei risultati:
\begin{myverbatim}
Nearest Neighbor ->              1.2470
Nearest Insertion ->             1.2157
Cheapest Insertion versione 3 -> 1.1782
Farthest Insertion ->            1.0852
Furthest Insertion versione 2 -> 1.1066
\end{myverbatim}
Ovvero, in media, Farthest si colloca al primo posto, mentre Furthest al secondo. Questo risultato è particolarmente rilevante in quanto Furthest Insertion è proprio l'euristica mancante in letteratura. Per completezza possiamo anche valutare la varianza delle soluzioni trovate:
\begin{myverbatim}
Nearest Neighbor ->              0.004980
Nearest Insertion ->             0.001458
Cheapest Insertion versione 3 -> 0.000897
Farthest Insertion ->            0.000885
Furthest Insertion versione 2 -> 0.001211
\end{myverbatim}
Da questi risultati possiamo concludere che Farthest e Cheapest ottengono risultati con una varianza molto bassa.

\subsection{Analisi dei tempi delle euristiche}
Possiamo allo stesso modo analizzare i tempi delle euristiche analizzate nella sezione precedente: \newline
\includegraphics[width=1\textwidth]{../Grafici/8.png} \
I tempi sono coerenti con le considerazioni sulle complessità temporale fatte in precedenza: Nearest Neighbor risulta essere l'algoritmo più veloce con complessità $O(n^2)$ ma come visto in precedenza in media trova soluzioni di qualità bassa, Nearest Insertion e Farthest Insertion hanno un tempo molto simile in quanto entrambi sono algoritmi $O(n^2)$ e condividono molto del codice, mentre Cheapest Insertion e Furthest Insertion anche in questo caso ottengono tempi molto simili e coerenti con la loro complessità temporale (analizzata nelle sezioni precedenti). \newline Complessivamente (in sintesi) possiamo affermare che Furthest Insertion trova in media ottime soluzioni (non le migliori) ma richiede più tempo rispetto alle altre euristiche (escluso Cheapest Insertion dove i tempi sono molto simili).

\section{Confronto tempi e qualità delle euristiche con istanze enormi}
In questa sezione analizziamo il comportamento delle euristiche nel caso di istanze molto grandi (con un numero di città maggiore uguale a 10000), analizzeremo tutte le istanze restanti presenti nella libreria TSP-LIB fino alla istanza di dimensione pari a 14051 città. Per ognuna di queste istanze, il parametro minimo per Cheapest Insertion è pari a 3. \newline
\subsection{Qualità delle soluzioni trovate per istanze grandi}
\includegraphics[width=1\textwidth]{../Grafici/18.png} \
Da questi risultati possiamo notare come Nearest Neighbor risulti essere in molti contesti l'euristica peggiore, mentre Farthest Insertion risulta essere la migliore. Inoltre Furthest Insertion sembra essere al secondo posto dopo Farthest Insertion dal punto di vista delle qualità trovate, infatti la media delle qualità è:
\begin{myverbatim}
Nearest Neighbor ->              1.2426
Nearest Insertion ->             1.2204
Cheapest Insertion versione 3 -> 1.1789
Farthest Insertion ->            1.1598
Furthest Insertion versione 2 -> 1.1943
\end{myverbatim}
Mentre invece la varianza della qualità per le istanze enormi risulta essere:
\begin{myverbatim}
Nearest Neighbor ->              0.00292
Nearest Insertion ->             0.00222
Cheapest Insertion versione 3 -> 0.00148
Farthest Insertion ->            0.00231
Furthest Insertion versione 2 -> 0.00378  
\end{myverbatim}
La varianza delle qualità per le istanze enormi risulta essere molto passa per Cheapest insertion e la più alta per Furthest Insertion. \newline
Possiamo quindi concludere che in media per le istanze grandi Furthest Insertion sia al secondo posto in termini di qualità delle soluzioni trovate rispetto a Cheapest Insertion.
\subsection{Tempi necessari per la risoluzione di istanze grandi}
Per quanto riguarda i tempi invece i risultati sono i seguenti: \newline
\includegraphics[width=1\textwidth]{../Grafici/19.png} \
Possiamo notare come i risultati siano totalmente in linea con i tempi per le istanze piccole: Nearest Neighbor risulta essere l'euristica più veloce, Farthest e Nearest Insertion risultano avere lo stesso tempo per ogni istanza (peggiore di Nearest Neighbor) mentre le euristiche più lente sono Cheapest e Furthest, dove però Furthest Insertion risulta essere leggermente più veloce di Cheapest Insertion.

\section{Analisi robustezza rispetto alla scelta delle città iniziali}
Abbiamo visto che l'inizializzazione del tour consiste nel determinare la coppia di città più vicine per gli algoritmi Nearest Neighbor, Nearest Insertion e Cheapest Insertion e consiste nel determinare la coppia di città più lontane per Farthest e Furthest Insertion. Questa sezione analizza il variare dei tempi e delle qualità delle soluzioni trovate al variare delle città iniziali. Per fare questo (come visto nella sezione delle implementazioni) l'implementazione resta la stessa tranne per il fatto che le due città iniziali sono scelte casualmente. Chiaramente si deve garantire che siano due città diverse. Vediamo i risultati prima dal punto di vista delle qualità, poi dei tempi.
\subsection{Robustezza della qualità della soluzione delle implementazioni}
Per prima cosa valutiamo la robustezza della qualità della soluzione, quindi iteriamo 100 volte (con un seed diverso per i numeri casuali) su ognuna delle prime 50 istanze da TSP-LIB in ordine di dimensione, ho deciso di limitarmi alle sole prime 30 città in quanto iterare 100 volte sull'esecuzione di tutte e 5 le euristiche richiede molto tempo. Per prima cosa considero la media delle soluzioni trovate per ogni istanza e per ogni algoritmo: \newline
\includegraphics[width=1\textwidth]{../Grafici/9.png} \
I risultati medi sono coerenti con i risultati ottenuti inizializzando il tour con la coppia di città più vicine/lontane: Furthest Insertion (nelle 50 città analizzate) e Farthest Insertion trovano in media un percorso migliore rispetto alle altre euristiche analizzate, trovando soluzioni tra 3-4\% e il 15\%, mentre le altre euristiche si collocano nel range 13-14\%-25\% (o 30\% nel caso di Nearest Neighbor). Inoltre in particolare Nearest Neighbor trova soluzioni (in media) peggiori rispetto alle altre euristiche. \newline 
Ora possiamo analizzare invece la varianza delle soluzioni trovate: vogliamo quindi sapere quanto le soluzioni sia allontanano dal valore medio trovato prima al variare dell'inizializzazione. Di seguito il grafico: \newline
\includegraphics[width=1\textwidth]{../Grafici/10.png} \
Possiamo notare come Nearest Neighbor ha una varianza elevata, quindi le soluzioni trovate distano molto dalla media (avvicinandosi o allontanandosi dall'ottimo). Dopodiché possiamo notare come Furthest Insertion e Farthest Insertion abbiano una varianza tra le più basse, andando a considerare la media delle varianze otteniamo:
\begin{myverbatim}
Nearest Neighbor ->              0.002190
Nearest Insertion ->             0.000709
Cheapest Insertion versione 3 -> 0.000909
Farthest Insertion ->            0.000431
Furthest Insertion versione 2 -> 0.000426
\end{myverbatim}
Da questi risultati possiamo notare come Furthest Insertion e Farthest Insertion abbiano la varianza più bassa (in media) tra le euristiche analizzate: questo è un altro risultato interessante, ovvero non solo trovano (in media) le soluzioni più vicine all'ottimo (con inizializzazione casuale e non) ma anche con una varianza bassa.
\subsection{Robustezza dei tempi delle implementazioni}
In questa sezione vogliamo invece vedere come variano i tempi delle implementazioni sempre con una inizializzazione casuale del tour. Come prima, innanzitutto analizziamo la media dei tempi e poi la varianza. \newline
\includegraphics[width=1\textwidth]{../Grafici/11.png} \
Anche in questo caso, i risultati non si allontano molto dai risultati ottenuti con l'inizializzazione delle città più vicine/lontane: Nearest Neighbor si conferma come euristica più veloce, dopodiché Nearest Insertion e Farthest Insertion ottengono tempi medi molto simili e infine Cheapest Insertion e Furthest Insertion ottengono tempi medi molto simili (i peggiori in modo coerente con la complessità temporale).  \newline
\includegraphics[width=1\textwidth]{../Grafici/12.png} \
Dal punto di vista invece della varianza dei tempi, possiamo notare una varianza molto bassa per i tempi per Nearest Neighbor, dopo (in ordine) una varianza bassa per Nearest Insertion e Farthest Insertion, poi Furthest Insertion con una varianza relativamente alta e infine Cheapest Insertion versione 3 con la varianza più alta per quanto riguarda i tempi.

\section{Analisi risultati medi e varianza di Random Insertion}
In questa sezione analizziamo le due versioni implementate di Random Insertion: la prima sceglie casualmente il nodo da inserire ma poi procede inserendolo nel punto che minimizza il costo di inserzione, mentre invece la seconda versione prende ancora casualmente un nodo da inserire ma poi lo inserisce casualmente. Di seguito il grafico che compara le qualità medie per le prime 50 istanze (sempre in ordine di dimensione) con 100 iterazioni per istanza: \newline
\includegraphics[width=1\textwidth]{../Grafici/13.png} \
Da questo grafico possiamo notare come le qualità trovate da Random Insertion 2 si allontanano troppo dall'ottimo (decine o centinaia di volte peggio dell'ottimo), mentre Random Insertion versione 1 presenta delle soluzioni accettabili. Possiamo confrontare i risultati medi di Random Insertion versione 1 con le altre euristiche, e otteniamo il seguente grafico: \newline
\includegraphics[width=1\textwidth]{../Grafici/14.png} \
Possiamo notare come Random Insertion ottiene, sorprendentemente, dei risultati ottimi, simili a Furthest Insertion e Farthest Insertion. Importante specificare che stiamo confrontando le euristiche basate su inserzione e Nearest Neighbor con la media delle 100 iterazioni di Random Insertion versione 1. \newline
\includegraphics[width=1\textwidth]{../Grafici/15.png} \
In questo grafico andiamo a considerare la varianza delle qualità delle soluzioni. Anche in questo caso, la varianza della versione 2 risulta maggiore della versione 1. Una possibile spiegazione può derivare dal fatto che la versione 2 implementa due aspetti totalmente in modo casuale (scelta del nodo e inserimento casuale) mentre la versione 1 fa una sola scelta casuale (scelta del nodo), per questo motivo è ragionevole il fatto che, complessivamente, la versione 2 ottenga costi totali più elevati. \newline
\includegraphics[width=1\textwidth]{../Grafici/16.png} \
Per quanto riguarda invece la media dei tempi, possiamo notare che la prima versione richiede sempre più tempo rispetto alla seconda in modo coerente con il fatto che la prima versione effettua una ricerca nel tour alla ricerca della posizione ottima, quindi con complessità pari a $O(n)$ mentre la seconda sceglie casualmente un punto di inserzione, la scelta casuale con istruzione \lstinline!random.randint(a, b)! ha complessità temporale pari a $O(1)$\footnote{https://docs.python.org/3/library/random.html}.\newline
\includegraphics[width=1\textwidth]{../Grafici/17.png} \
Invece per la varianza dei tempi, notiamo anche qui che la seconda versione ha una varianza bassissima per i tempi in quanto le istruzioni necessarie dipendono poco dalla dimensione dell'input (\lstinline!random.randint(0, n)! ha complessità $O(1)$ indipendentemente dalla dimensione di n). \newline

\section{Analisi risultati su Istanze Casuali}
Per completezza, sono stati ottenuti i risultati su istanze casuali, ovvero istanze dove la matrice di adiacenza è ottenuta casualmente. Inoltre si verifica che valga la disuguaglianza triangolare, ovvero che il costo $c_{ij}$ per una coppia generica di nodi $i$ e $j$, non può mai essere strettamente maggiore della somma di $c_{ik}$ e $c_{kj}$ (detto in altre parole, un lato di un triangolo non degenere non può mai essere maggiore della somma degli altri due lati), in tal caso si assegna un nuovo costo che verifichi la disuguaglianza. Di seguito il codice che genera la matrice casuale:
\begin{python}
def generate_adjacency_matrix(self, n, max_weight=100):
  self.numCity = n
  D = np.random.randint(1, max_weight + 1, size=(n, n)) 
  D = (D + D.T) / 2
  np.fill_diagonal(D, 0)
  for k in range(n):
    for i in range(n):
      for j in range(n):
        if D[i][j] > D[i][k] + D[k][j]:
          D[i][j] = D[i][k] + D[k][j]
  self.adj = D
\end{python}
\subsection{Analisi media delle qualità e dei tempi}
Sono stati ottenuti i risultati su 20 iterazioni (sempre con istanze casuali) di istanze con dimensione da 50 incluso a 100 escluso. Per ogni dimensione delle città (50, 51...) è stata ottenuta la media e la varianza delle 20 iterazioni per quanto riguarda la qualità trovata e i tempi. \newline
\includegraphics[width=1\textwidth]{../Grafici/20.png} \
Possiamo notare come (sorprendentemente) Nearest Neighbor per istanze casuali trovi, in media, soluzioni di qualità migliore rispetto alle euristiche basate su inserzione. Invece possiamo notare qualità medie simili tra le euristiche basate su inserzione. Le qualità mostrate nel grafico sono "assolute" in quanto (essendo istanze generate casualmente) non è nota la soluzione ottima. \newline
\includegraphics[width=1\textwidth]{../Grafici/21.png} \
I risultati sui tempi medi sono coerenti con i risultati visti nelle sezioni precedenti, ovvero Nearest Neighbor risulta essere l'euristica più veloce, al secondo posto sono presenti Farthest e Nearest Insertion e poi Furthest e Cheapest Insertion.
\subsection{Analisi varianza delle qualità e dei tempi}
\includegraphics[width=1\textwidth]{../Grafici/22.png} \
Adesso invece valutiamo la varianza dei risultati ottenuti, possiamo notare una varianza molto alta: questo può essere spiegabile in quanto due istanze generate casualmente (anche con la stessa dimensione) risultano essere molto diverse e quindi si ottengono soluzioni di qualità molto diverse. La media delle varianze risulta essere:
\begin{myverbatim}
Nearest Neighbor ->              2969.98
Nearest Insertion ->             3288.40
Cheapest Insertion versione 3 -> 3256.91
Farthest Insertion ->            3468.87
Furthest Insertion versione 2 -> 3677.23
\end{myverbatim}
Quindi Nearest Neighbor ottiene una varianza media più bassa mentre Furthest una varianza media più alta. \newline
\includegraphics[width=1\textwidth]{../Grafici/23.png} \
Per quanto riguarda invece la varianza dei tempi, possiamo notare, nell'ordine dalla varianza più bassa a quella più alta, i seguenti risultati: Nearest Neighbor, Nearest e Farthest Insertion e poi Furthest e Cheapest Insertion. \newline
Possiamo quindi concludere che, per le istanze generate casualmente, in media Nearest Neighbor si comporta meglio rispetto alle altre euristiche analizzate.

\chapter{Conclusioni}
Si può concludere la tesi riassumendo i risultati trovati:
\begin{legal}
  \item Furthest Insertion versione 3 approssimata necessita una $m_{ott}$ più alta rispetto a Cheapest Insertion versione 3 approssimata: per questo motivo l'ottimizzazione non ha portato ad un significativo miglioramento dei tempi per quanto riguarda Furthest Insertion mentre lo ha portato per Cheapest Insertion.
  \item Il confronto sulle prime 50 istanze ha mostrato come Farthest Insertion risulta essere la migliore euristica per quanto riguarda le qualità trovate, Furthest Insertion risulta essere la seconda, Nearest Neighbor invece risulta essere la peggiore.
  \item Per quanto riguarda i tempi, Nearest Neighbor risulta essere l'euristica più veloce, subito dopo ci sono Farthest e Nearest Insertion e le euristiche più lente sono Cheapest e Furthest Insertion (in modo coerente con la complessità temporale)
  \item Per quanto riguarda le istanze enormi (da 1000 a 14 mila città) sono stati trovati risultati simili alle istanze piccole: Farthest e Furthest sono le migliori euristiche e Nearest Neighbor la peggiore.
  \item Random Insertion trova soluzioni buone, come Furthest e Farthest insertion in modo inatteso in quanto, appunto, sceglie i nodi da inserire casualmente.
  \item Nel caso di istanze generate casualmente, Nearest Neighbor risulta essere l'euristica migliore (in contrasto con i risultati trovati prima) mentre le altre euristiche si sono comportate in modo simile tra loro.
\end{legal}
Questi risultati sono molto interessanti in quanto Furthest Insertion è proprio l'euristica mancante in letteratura, ad esempio nel "The Traveling Salesman" di G. Reinelt\cite{Reinelt}, possiamo trovare Nearest Insertion (6.2.1.1), varie versioni di Farthest Insertion (6.2.1.2), varie versioni di Cheapest Insertion (6.2.1.5) ma non Furthest Insertion.

\subsection{Possibili sviluppi e estensioni}
Sicuramente sarebbe interessante estendere il progetto nei seguenti campi:
\begin{legal}
  \item Implementare altre euristiche (ad esempio non basate su inserzione) e confrontarle con la nuova euristica proposta in questa tesi.
  \item Può essere interessante estendere il progetto ad istanze a 3 dimensioni o istanze con distanze diverse dalla distanza euclidea in due dimensioni, ad esempio con la distanza di Čebyšëv e confrontare le prestazioni dell'euristica al variare del parametro $k$\footnote{https://www.researchgate.net/publication/311633774\_Chebyshev\_Distance}, oppure ad esempio la distanza di Manhattan\footnote{https://xlinux.nist.gov/dads/HTML/manhattanDistance.html}.
  \item Implementare gli stessi algoritmi in altri linguaggi di programmazione (come C, C++ o Java), confrontare eventuali lati negativi, positivi e le prestazioni
\end{legal}.
 
%
%			BIBLIOGRAFIA
%

\begin{thebibliography}{00}
\bibitem{Menger}
Traveling Salesman Problem, F. Greco, IntechOpen, 2008.
\bibitem{TSP formulation}
M. Velednitsky, Short Combinatorial Proof that the DFJ Polytope is contained in
the MTZ Polytope for the Asymmetric Traveling Salesman Problem, UC Berkeley, 2018.
%
\bibitem{Analysis of Brute Force}
Analysis of Brute Force and Branch \& Bound Algorithms to solve the Traveling
Salesperson Problem (TSP), Informatics Department, Engineering Faculty, Widyatama University, 2021.
%
\bibitem{Branch and Bound}
T. G. Crainic, B. Le Cun, C. Roucairol, Parallel Branch-and-Bound Algorithms, Département de management et technologie École des Sciences de la Gestion Université du Québec à Montréal and CIRRELT, Canada
\bibitem{Branch and Cut Algoritmhs}
Yuan Yuan, Diego Cattaruzza, Maxime Ogier, Frederic Semet. A branch-and-cut algorithm for the generalized traveling salesman problem with time windows. European Journal of Operational Research, 2020, 286 (3)
%
\bibitem{TSP NP Completezza}
R. Karp, Complexity of the Traveling Salesman Problem, New York, Plenum (1972), 85–103
%
\bibitem{Reinelt}
G. Reinelt, The Traveling Salesman: Computational Solution for TSP Applications, Heidelberg, Springer-Verlag (1994)
\bibitem{Branch and Cut}
J.E. Mitchell, Branch-and-cut algorithms for combinatorial
optimization problems, in Handbook of applied optimization, P.M.
Pardalos and M.G.C. Resende eds., Oxford University Press, 2000
\bibitem{Local Search}
Olaf Mersmann, Bernd Bischl, Jakob Bossek, Heike Trautmann, Markus Wagner, Frank Neumann, Local Search and the Traveling Salesman Problem: A Feature-Based Characterization of Problem Hardness, Statistics Faculty, TU Dortmund University, Germany
\bibitem{2OPT}
Matthias Englert, Heiko Röglin, Berthold Vöcking, Worst Case and Probabilistic Analysis 
of the 2-Opt Algorithm for the TSP, Dept. of Computer Science, RWTH Aachen University
\bibitem{LK}
S. Lin, B. W. Kernighan, An Effective Heuristic Algorithm for the Traveling-Salesman Problem, Bell Telephone Laboratories, Incorporated, Murray Hill, N.J., 1971
\bibitem{Helsgaun}
K. Helsgaun, An effective implementation of the Lin-Kernighan traveling
salesman heuristic, Department of Computer Science, Roskilde Universit, 13 April 1999
\bibitem{knuthart}
Donald E. Knuth, The Art of Computer Programming: Volume 2 (Seminumerical Algorithms), Addison-Wesley Professional, 1997, Capitolo 3
\bibitem{Rosenkrantz}
Daniel J. Rosenkrantz, Richard E. Stearns, Philip M. Lewis II, An Analysis of Several Heuristics for the Traveling Salesman Problem, SIAM Journal on Computing, 1977

\end{thebibliography}
\end{document}